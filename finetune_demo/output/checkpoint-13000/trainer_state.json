{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.11343903524463564,
  "eval_steps": 500,
  "global_step": 13000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 4.003945827484131,
      "learning_rate": 4.9975e-05,
      "loss": 4.4422,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.4430253505706787,
      "learning_rate": 4.995e-05,
      "loss": 4.9148,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.353320598602295,
      "learning_rate": 4.992500000000001e-05,
      "loss": 4.6807,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.825360298156738,
      "learning_rate": 4.99e-05,
      "loss": 4.7521,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.723774433135986,
      "learning_rate": 4.9875000000000006e-05,
      "loss": 4.2947,
      "step": 50
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.8468194007873535,
      "learning_rate": 4.9850000000000006e-05,
      "loss": 4.2023,
      "step": 60
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.237310886383057,
      "learning_rate": 4.9825000000000005e-05,
      "loss": 3.8158,
      "step": 70
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.8756794929504395,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 3.8146,
      "step": 80
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.009667873382568,
      "learning_rate": 4.9775000000000004e-05,
      "loss": 3.525,
      "step": 90
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.398678779602051,
      "learning_rate": 4.975e-05,
      "loss": 4.0033,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.986671447753906,
      "learning_rate": 4.9725e-05,
      "loss": 3.7559,
      "step": 110
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.168197154998779,
      "learning_rate": 4.97e-05,
      "loss": 4.0166,
      "step": 120
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.3408074378967285,
      "learning_rate": 4.967500000000001e-05,
      "loss": 3.8406,
      "step": 130
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.339646816253662,
      "learning_rate": 4.965e-05,
      "loss": 3.6691,
      "step": 140
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.627079010009766,
      "learning_rate": 4.962500000000001e-05,
      "loss": 3.4582,
      "step": 150
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.970555782318115,
      "learning_rate": 4.96e-05,
      "loss": 3.6629,
      "step": 160
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.026618957519531,
      "learning_rate": 4.9575000000000006e-05,
      "loss": 3.6361,
      "step": 170
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.33371114730835,
      "learning_rate": 4.9550000000000005e-05,
      "loss": 3.9473,
      "step": 180
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.154473304748535,
      "learning_rate": 4.9525000000000004e-05,
      "loss": 3.7174,
      "step": 190
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.5811638832092285,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.6871,
      "step": 200
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.73746395111084,
      "learning_rate": 4.9475e-05,
      "loss": 3.35,
      "step": 210
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.879167079925537,
      "learning_rate": 4.945e-05,
      "loss": 3.7342,
      "step": 220
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.817676544189453,
      "learning_rate": 4.9425e-05,
      "loss": 3.5229,
      "step": 230
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.01377534866333,
      "learning_rate": 4.94e-05,
      "loss": 3.7477,
      "step": 240
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.8102521896362305,
      "learning_rate": 4.937500000000001e-05,
      "loss": 3.5217,
      "step": 250
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.032114028930664,
      "learning_rate": 4.935e-05,
      "loss": 3.5686,
      "step": 260
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.951850891113281,
      "learning_rate": 4.9325000000000006e-05,
      "loss": 3.5703,
      "step": 270
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.507918357849121,
      "learning_rate": 4.93e-05,
      "loss": 3.5629,
      "step": 280
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.570035457611084,
      "learning_rate": 4.9275000000000005e-05,
      "loss": 3.5367,
      "step": 290
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.869936943054199,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 3.6342,
      "step": 300
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.799006462097168,
      "learning_rate": 4.9225000000000004e-05,
      "loss": 3.6252,
      "step": 310
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.177751541137695,
      "learning_rate": 4.92e-05,
      "loss": 3.4201,
      "step": 320
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.65067195892334,
      "learning_rate": 4.9175e-05,
      "loss": 3.3645,
      "step": 330
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.059357643127441,
      "learning_rate": 4.915e-05,
      "loss": 3.5406,
      "step": 340
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.486085891723633,
      "learning_rate": 4.9125e-05,
      "loss": 3.4359,
      "step": 350
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.304466724395752,
      "learning_rate": 4.91e-05,
      "loss": 3.4551,
      "step": 360
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.683356761932373,
      "learning_rate": 4.907500000000001e-05,
      "loss": 3.5348,
      "step": 370
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.155732154846191,
      "learning_rate": 4.905e-05,
      "loss": 3.5824,
      "step": 380
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.893853187561035,
      "learning_rate": 4.9025000000000006e-05,
      "loss": 3.5844,
      "step": 390
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.101118087768555,
      "learning_rate": 4.9e-05,
      "loss": 3.3674,
      "step": 400
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.032453536987305,
      "learning_rate": 4.8975000000000005e-05,
      "loss": 3.2695,
      "step": 410
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.15272331237793,
      "learning_rate": 4.8950000000000004e-05,
      "loss": 3.6684,
      "step": 420
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.86474895477295,
      "learning_rate": 4.8925e-05,
      "loss": 3.5078,
      "step": 430
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.608808517456055,
      "learning_rate": 4.89e-05,
      "loss": 3.2803,
      "step": 440
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.507441520690918,
      "learning_rate": 4.8875e-05,
      "loss": 3.702,
      "step": 450
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.847699165344238,
      "learning_rate": 4.885e-05,
      "loss": 3.8023,
      "step": 460
    },
    {
      "epoch": 0.0,
      "grad_norm": 13.367390632629395,
      "learning_rate": 4.8825e-05,
      "loss": 3.8279,
      "step": 470
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.296418190002441,
      "learning_rate": 4.88e-05,
      "loss": 3.2896,
      "step": 480
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.875416278839111,
      "learning_rate": 4.8775000000000007e-05,
      "loss": 3.3676,
      "step": 490
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.522693634033203,
      "learning_rate": 4.875e-05,
      "loss": 3.4178,
      "step": 500
    },
    {
      "epoch": 0.0,
      "eval_bleu-4": 0.031024109617994847,
      "eval_rouge-1": 30.057662,
      "eval_rouge-2": 6.500522,
      "eval_rouge-l": 24.025660000000002,
      "eval_runtime": 57.5126,
      "eval_samples_per_second": 0.869,
      "eval_steps_per_second": 0.07,
      "step": 500
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.285541534423828,
      "learning_rate": 4.8725000000000005e-05,
      "loss": 3.4706,
      "step": 510
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.83202838897705,
      "learning_rate": 4.87e-05,
      "loss": 3.4533,
      "step": 520
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.996515274047852,
      "learning_rate": 4.8675000000000004e-05,
      "loss": 3.6318,
      "step": 530
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.272391319274902,
      "learning_rate": 4.8650000000000003e-05,
      "loss": 3.4602,
      "step": 540
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.579452514648438,
      "learning_rate": 4.8625e-05,
      "loss": 3.4443,
      "step": 550
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.816397666931152,
      "learning_rate": 4.86e-05,
      "loss": 3.5934,
      "step": 560
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.341827392578125,
      "learning_rate": 4.8575e-05,
      "loss": 3.5416,
      "step": 570
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.944087982177734,
      "learning_rate": 4.855e-05,
      "loss": 3.4496,
      "step": 580
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.996173858642578,
      "learning_rate": 4.8525e-05,
      "loss": 3.7486,
      "step": 590
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.106121063232422,
      "learning_rate": 4.85e-05,
      "loss": 3.2885,
      "step": 600
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.600500106811523,
      "learning_rate": 4.8475000000000006e-05,
      "loss": 3.4143,
      "step": 610
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.488389015197754,
      "learning_rate": 4.845e-05,
      "loss": 3.6098,
      "step": 620
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.938203811645508,
      "learning_rate": 4.8425000000000005e-05,
      "loss": 3.6313,
      "step": 630
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.382744789123535,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 3.5857,
      "step": 640
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.71755313873291,
      "learning_rate": 4.8375000000000004e-05,
      "loss": 3.3309,
      "step": 650
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.071805953979492,
      "learning_rate": 4.835e-05,
      "loss": 3.4773,
      "step": 660
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.35904598236084,
      "learning_rate": 4.8325e-05,
      "loss": 3.4977,
      "step": 670
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.724100589752197,
      "learning_rate": 4.83e-05,
      "loss": 3.4553,
      "step": 680
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.169225692749023,
      "learning_rate": 4.8275e-05,
      "loss": 3.4496,
      "step": 690
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.290278434753418,
      "learning_rate": 4.825e-05,
      "loss": 3.2531,
      "step": 700
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.294111251831055,
      "learning_rate": 4.822500000000001e-05,
      "loss": 3.5395,
      "step": 710
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.734617233276367,
      "learning_rate": 4.82e-05,
      "loss": 3.407,
      "step": 720
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.563068389892578,
      "learning_rate": 4.8175000000000005e-05,
      "loss": 3.44,
      "step": 730
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.062426567077637,
      "learning_rate": 4.815e-05,
      "loss": 3.5178,
      "step": 740
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.489798545837402,
      "learning_rate": 4.8125000000000004e-05,
      "loss": 3.2133,
      "step": 750
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.393692016601562,
      "learning_rate": 4.8100000000000004e-05,
      "loss": 3.4357,
      "step": 760
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.083050727844238,
      "learning_rate": 4.8075e-05,
      "loss": 3.4592,
      "step": 770
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.281061172485352,
      "learning_rate": 4.805e-05,
      "loss": 3.383,
      "step": 780
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.884364128112793,
      "learning_rate": 4.8025e-05,
      "loss": 3.4457,
      "step": 790
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.984369277954102,
      "learning_rate": 4.8e-05,
      "loss": 3.3375,
      "step": 800
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.45559310913086,
      "learning_rate": 4.7975e-05,
      "loss": 3.3205,
      "step": 810
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.363953590393066,
      "learning_rate": 4.795e-05,
      "loss": 3.3885,
      "step": 820
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.458094596862793,
      "learning_rate": 4.7925000000000006e-05,
      "loss": 3.5455,
      "step": 830
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.769548416137695,
      "learning_rate": 4.79e-05,
      "loss": 3.4146,
      "step": 840
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.27065372467041,
      "learning_rate": 4.7875000000000005e-05,
      "loss": 3.391,
      "step": 850
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.004778861999512,
      "learning_rate": 4.785e-05,
      "loss": 3.7289,
      "step": 860
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.780348777770996,
      "learning_rate": 4.7825000000000004e-05,
      "loss": 3.3852,
      "step": 870
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.862414360046387,
      "learning_rate": 4.78e-05,
      "loss": 3.4115,
      "step": 880
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.986166000366211,
      "learning_rate": 4.7775e-05,
      "loss": 3.6943,
      "step": 890
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.642940044403076,
      "learning_rate": 4.775e-05,
      "loss": 3.3514,
      "step": 900
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.582789421081543,
      "learning_rate": 4.7725e-05,
      "loss": 3.3094,
      "step": 910
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.666740417480469,
      "learning_rate": 4.77e-05,
      "loss": 3.2605,
      "step": 920
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.743289947509766,
      "learning_rate": 4.7675e-05,
      "loss": 3.5164,
      "step": 930
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.174683570861816,
      "learning_rate": 4.765e-05,
      "loss": 3.2162,
      "step": 940
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.771038055419922,
      "learning_rate": 4.7625000000000006e-05,
      "loss": 3.201,
      "step": 950
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.359173774719238,
      "learning_rate": 4.76e-05,
      "loss": 3.4635,
      "step": 960
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.499608039855957,
      "learning_rate": 4.7575000000000004e-05,
      "loss": 3.2055,
      "step": 970
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.294612884521484,
      "learning_rate": 4.755e-05,
      "loss": 3.4055,
      "step": 980
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.114166259765625,
      "learning_rate": 4.7525e-05,
      "loss": 3.318,
      "step": 990
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.859212875366211,
      "learning_rate": 4.75e-05,
      "loss": 3.4912,
      "step": 1000
    },
    {
      "epoch": 0.01,
      "eval_bleu-4": 0.028869023083259095,
      "eval_rouge-1": 28.749138000000002,
      "eval_rouge-2": 6.051848,
      "eval_rouge-l": 23.176414000000005,
      "eval_runtime": 41.2867,
      "eval_samples_per_second": 1.211,
      "eval_steps_per_second": 0.097,
      "step": 1000
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.912551879882812,
      "learning_rate": 4.7475e-05,
      "loss": 3.3793,
      "step": 1010
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.791126251220703,
      "learning_rate": 4.745e-05,
      "loss": 3.4934,
      "step": 1020
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.523967742919922,
      "learning_rate": 4.7425e-05,
      "loss": 3.6701,
      "step": 1030
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.04207706451416,
      "learning_rate": 4.74e-05,
      "loss": 3.3959,
      "step": 1040
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.053603172302246,
      "learning_rate": 4.7375e-05,
      "loss": 3.2523,
      "step": 1050
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.099428176879883,
      "learning_rate": 4.735e-05,
      "loss": 3.376,
      "step": 1060
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.28054141998291,
      "learning_rate": 4.7325000000000005e-05,
      "loss": 3.5193,
      "step": 1070
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.747491836547852,
      "learning_rate": 4.73e-05,
      "loss": 3.5561,
      "step": 1080
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.161296844482422,
      "learning_rate": 4.7275000000000004e-05,
      "loss": 3.4957,
      "step": 1090
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.71081829071045,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 3.5168,
      "step": 1100
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.940583229064941,
      "learning_rate": 4.7225e-05,
      "loss": 3.4107,
      "step": 1110
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.288482666015625,
      "learning_rate": 4.72e-05,
      "loss": 3.3135,
      "step": 1120
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.872213363647461,
      "learning_rate": 4.7175e-05,
      "loss": 3.3551,
      "step": 1130
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.6473388671875,
      "learning_rate": 4.715e-05,
      "loss": 3.6742,
      "step": 1140
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.840178489685059,
      "learning_rate": 4.7125e-05,
      "loss": 3.4475,
      "step": 1150
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.022444725036621,
      "learning_rate": 4.71e-05,
      "loss": 3.402,
      "step": 1160
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.65376091003418,
      "learning_rate": 4.7075e-05,
      "loss": 3.3564,
      "step": 1170
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.410982131958008,
      "learning_rate": 4.705e-05,
      "loss": 3.2943,
      "step": 1180
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.157048225402832,
      "learning_rate": 4.7025000000000005e-05,
      "loss": 3.534,
      "step": 1190
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.30816650390625,
      "learning_rate": 4.7e-05,
      "loss": 3.3176,
      "step": 1200
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.67281436920166,
      "learning_rate": 4.6975000000000003e-05,
      "loss": 3.248,
      "step": 1210
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.744232177734375,
      "learning_rate": 4.695e-05,
      "loss": 3.4057,
      "step": 1220
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.301743507385254,
      "learning_rate": 4.6925e-05,
      "loss": 3.1994,
      "step": 1230
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.627485275268555,
      "learning_rate": 4.69e-05,
      "loss": 3.3982,
      "step": 1240
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.435761451721191,
      "learning_rate": 4.6875e-05,
      "loss": 3.365,
      "step": 1250
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.372668266296387,
      "learning_rate": 4.685000000000001e-05,
      "loss": 3.5189,
      "step": 1260
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.463290214538574,
      "learning_rate": 4.6825e-05,
      "loss": 3.41,
      "step": 1270
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.3929443359375,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 3.559,
      "step": 1280
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.597900390625,
      "learning_rate": 4.6775000000000005e-05,
      "loss": 3.5143,
      "step": 1290
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.86735725402832,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 3.2307,
      "step": 1300
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.52495002746582,
      "learning_rate": 4.6725000000000004e-05,
      "loss": 3.073,
      "step": 1310
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.870905876159668,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 3.2627,
      "step": 1320
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.020086288452148,
      "learning_rate": 4.6675e-05,
      "loss": 3.335,
      "step": 1330
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.948063850402832,
      "learning_rate": 4.665e-05,
      "loss": 3.3463,
      "step": 1340
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.237268447875977,
      "learning_rate": 4.6625e-05,
      "loss": 3.6533,
      "step": 1350
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.650522232055664,
      "learning_rate": 4.660000000000001e-05,
      "loss": 3.0871,
      "step": 1360
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.745450973510742,
      "learning_rate": 4.6575e-05,
      "loss": 3.259,
      "step": 1370
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.082151412963867,
      "learning_rate": 4.655000000000001e-05,
      "loss": 3.5232,
      "step": 1380
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.634358406066895,
      "learning_rate": 4.6525e-05,
      "loss": 3.4441,
      "step": 1390
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.807629585266113,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.2086,
      "step": 1400
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.533228874206543,
      "learning_rate": 4.6475000000000005e-05,
      "loss": 3.626,
      "step": 1410
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.629549980163574,
      "learning_rate": 4.6450000000000004e-05,
      "loss": 3.3463,
      "step": 1420
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.3773832321167,
      "learning_rate": 4.6425000000000004e-05,
      "loss": 3.3924,
      "step": 1430
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.773202896118164,
      "learning_rate": 4.64e-05,
      "loss": 3.4549,
      "step": 1440
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.574204444885254,
      "learning_rate": 4.6375e-05,
      "loss": 3.475,
      "step": 1450
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.244417190551758,
      "learning_rate": 4.635e-05,
      "loss": 3.1574,
      "step": 1460
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.584057807922363,
      "learning_rate": 4.6325e-05,
      "loss": 3.2512,
      "step": 1470
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.009052276611328,
      "learning_rate": 4.630000000000001e-05,
      "loss": 3.0418,
      "step": 1480
    },
    {
      "epoch": 0.01,
      "grad_norm": 7.7592058181762695,
      "learning_rate": 4.6275e-05,
      "loss": 3.3723,
      "step": 1490
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.008132934570312,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 3.2738,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "eval_bleu-4": 0.027913585134639294,
      "eval_rouge-1": 29.813835999999995,
      "eval_rouge-2": 5.687659999999999,
      "eval_rouge-l": 23.562042,
      "eval_runtime": 53.4632,
      "eval_samples_per_second": 0.935,
      "eval_steps_per_second": 0.075,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.790523529052734,
      "learning_rate": 4.6225e-05,
      "loss": 3.3465,
      "step": 1510
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.341552734375,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 3.4996,
      "step": 1520
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.913261413574219,
      "learning_rate": 4.6175000000000004e-05,
      "loss": 3.2926,
      "step": 1530
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.350922584533691,
      "learning_rate": 4.6150000000000004e-05,
      "loss": 3.4244,
      "step": 1540
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.082294464111328,
      "learning_rate": 4.6125e-05,
      "loss": 3.65,
      "step": 1550
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.8856201171875,
      "learning_rate": 4.61e-05,
      "loss": 3.3305,
      "step": 1560
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.903980255126953,
      "learning_rate": 4.6075e-05,
      "loss": 3.2756,
      "step": 1570
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.676593780517578,
      "learning_rate": 4.605e-05,
      "loss": 3.366,
      "step": 1580
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.318010330200195,
      "learning_rate": 4.6025e-05,
      "loss": 3.4162,
      "step": 1590
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.5108642578125,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.29,
      "step": 1600
    },
    {
      "epoch": 0.01,
      "grad_norm": 15.699606895446777,
      "learning_rate": 4.5975e-05,
      "loss": 3.6418,
      "step": 1610
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.15046501159668,
      "learning_rate": 4.5950000000000006e-05,
      "loss": 3.3992,
      "step": 1620
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.474068641662598,
      "learning_rate": 4.5925e-05,
      "loss": 3.6176,
      "step": 1630
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.819123268127441,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 3.599,
      "step": 1640
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.610997200012207,
      "learning_rate": 4.5875000000000004e-05,
      "loss": 3.2039,
      "step": 1650
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.110586166381836,
      "learning_rate": 4.585e-05,
      "loss": 3.2811,
      "step": 1660
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.946566581726074,
      "learning_rate": 4.5825e-05,
      "loss": 3.3477,
      "step": 1670
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.491862297058105,
      "learning_rate": 4.58e-05,
      "loss": 3.6553,
      "step": 1680
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.832290649414062,
      "learning_rate": 4.5775e-05,
      "loss": 3.3756,
      "step": 1690
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.163127899169922,
      "learning_rate": 4.575e-05,
      "loss": 3.4289,
      "step": 1700
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.788738250732422,
      "learning_rate": 4.5725e-05,
      "loss": 3.5061,
      "step": 1710
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.207480430603027,
      "learning_rate": 4.5700000000000006e-05,
      "loss": 3.5748,
      "step": 1720
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.022433280944824,
      "learning_rate": 4.5675e-05,
      "loss": 3.2248,
      "step": 1730
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.651362419128418,
      "learning_rate": 4.5650000000000005e-05,
      "loss": 3.2387,
      "step": 1740
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.777490615844727,
      "learning_rate": 4.5625e-05,
      "loss": 3.1766,
      "step": 1750
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.026676177978516,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 3.4482,
      "step": 1760
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.772842407226562,
      "learning_rate": 4.5575e-05,
      "loss": 3.0301,
      "step": 1770
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.364822387695312,
      "learning_rate": 4.555e-05,
      "loss": 3.2311,
      "step": 1780
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.431487083435059,
      "learning_rate": 4.5525e-05,
      "loss": 3.3699,
      "step": 1790
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.321239471435547,
      "learning_rate": 4.55e-05,
      "loss": 3.5357,
      "step": 1800
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.880449295043945,
      "learning_rate": 4.5475e-05,
      "loss": 3.2848,
      "step": 1810
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.665304183959961,
      "learning_rate": 4.545000000000001e-05,
      "loss": 3.1709,
      "step": 1820
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.57453727722168,
      "learning_rate": 4.5425e-05,
      "loss": 3.1229,
      "step": 1830
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.770709037780762,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 3.3529,
      "step": 1840
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.08707332611084,
      "learning_rate": 4.5375e-05,
      "loss": 3.4922,
      "step": 1850
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.601414680480957,
      "learning_rate": 4.5350000000000005e-05,
      "loss": 3.4846,
      "step": 1860
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.21180534362793,
      "learning_rate": 4.5325000000000004e-05,
      "loss": 3.2291,
      "step": 1870
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.844776153564453,
      "learning_rate": 4.53e-05,
      "loss": 3.4605,
      "step": 1880
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.804645538330078,
      "learning_rate": 4.5275e-05,
      "loss": 3.3508,
      "step": 1890
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.187294006347656,
      "learning_rate": 4.525e-05,
      "loss": 3.1187,
      "step": 1900
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.224065780639648,
      "learning_rate": 4.5225e-05,
      "loss": 3.2318,
      "step": 1910
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.493819236755371,
      "learning_rate": 4.52e-05,
      "loss": 3.5096,
      "step": 1920
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.184113502502441,
      "learning_rate": 4.5175e-05,
      "loss": 3.175,
      "step": 1930
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.4654541015625,
      "learning_rate": 4.5150000000000006e-05,
      "loss": 3.4561,
      "step": 1940
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.91032600402832,
      "learning_rate": 4.5125e-05,
      "loss": 2.99,
      "step": 1950
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.712696075439453,
      "learning_rate": 4.5100000000000005e-05,
      "loss": 3.4766,
      "step": 1960
    },
    {
      "epoch": 0.02,
      "grad_norm": 14.665224075317383,
      "learning_rate": 4.5075e-05,
      "loss": 3.4502,
      "step": 1970
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.373509407043457,
      "learning_rate": 4.5050000000000004e-05,
      "loss": 3.6313,
      "step": 1980
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.09035587310791,
      "learning_rate": 4.5025000000000003e-05,
      "loss": 3.4508,
      "step": 1990
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.840405464172363,
      "learning_rate": 4.5e-05,
      "loss": 3.2309,
      "step": 2000
    },
    {
      "epoch": 0.02,
      "eval_bleu-4": 0.030290881488117528,
      "eval_rouge-1": 31.928853999999998,
      "eval_rouge-2": 6.403686,
      "eval_rouge-l": 24.143422,
      "eval_runtime": 40.6242,
      "eval_samples_per_second": 1.231,
      "eval_steps_per_second": 0.098,
      "step": 2000
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.095232963562012,
      "learning_rate": 4.4975e-05,
      "loss": 3.1137,
      "step": 2010
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.557215690612793,
      "learning_rate": 4.495e-05,
      "loss": 3.2889,
      "step": 2020
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.857588768005371,
      "learning_rate": 4.4925e-05,
      "loss": 3.2441,
      "step": 2030
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.048416137695312,
      "learning_rate": 4.49e-05,
      "loss": 3.1584,
      "step": 2040
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.38164234161377,
      "learning_rate": 4.4875e-05,
      "loss": 3.2672,
      "step": 2050
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.740133285522461,
      "learning_rate": 4.4850000000000006e-05,
      "loss": 3.6094,
      "step": 2060
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.217506408691406,
      "learning_rate": 4.4825e-05,
      "loss": 3.3658,
      "step": 2070
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.488740921020508,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 3.443,
      "step": 2080
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.610937118530273,
      "learning_rate": 4.4775e-05,
      "loss": 3.5156,
      "step": 2090
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.791566848754883,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 3.5146,
      "step": 2100
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.467692375183105,
      "learning_rate": 4.4725e-05,
      "loss": 3.4672,
      "step": 2110
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.555472373962402,
      "learning_rate": 4.47e-05,
      "loss": 3.2504,
      "step": 2120
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.178323745727539,
      "learning_rate": 4.4675e-05,
      "loss": 3.2717,
      "step": 2130
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.644577026367188,
      "learning_rate": 4.465e-05,
      "loss": 3.3885,
      "step": 2140
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.547258377075195,
      "learning_rate": 4.4625e-05,
      "loss": 3.3535,
      "step": 2150
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.153543472290039,
      "learning_rate": 4.46e-05,
      "loss": 3.3236,
      "step": 2160
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.994660377502441,
      "learning_rate": 4.4575e-05,
      "loss": 3.2691,
      "step": 2170
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.253019332885742,
      "learning_rate": 4.4550000000000005e-05,
      "loss": 3.7012,
      "step": 2180
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.835092544555664,
      "learning_rate": 4.4525e-05,
      "loss": 3.2926,
      "step": 2190
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.340995788574219,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.2059,
      "step": 2200
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.025156021118164,
      "learning_rate": 4.4475e-05,
      "loss": 3.5123,
      "step": 2210
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.53663444519043,
      "learning_rate": 4.445e-05,
      "loss": 3.5639,
      "step": 2220
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.548942565917969,
      "learning_rate": 4.4425e-05,
      "loss": 3.4588,
      "step": 2230
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.573066711425781,
      "learning_rate": 4.44e-05,
      "loss": 3.542,
      "step": 2240
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.977300643920898,
      "learning_rate": 4.4375e-05,
      "loss": 3.4656,
      "step": 2250
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.264260292053223,
      "learning_rate": 4.435e-05,
      "loss": 3.2879,
      "step": 2260
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.861675262451172,
      "learning_rate": 4.4325e-05,
      "loss": 3.4334,
      "step": 2270
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.443397521972656,
      "learning_rate": 4.43e-05,
      "loss": 3.335,
      "step": 2280
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.039726257324219,
      "learning_rate": 4.4275e-05,
      "loss": 3.158,
      "step": 2290
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.476183891296387,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 3.2736,
      "step": 2300
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.614240646362305,
      "learning_rate": 4.4225e-05,
      "loss": 3.2504,
      "step": 2310
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.24009895324707,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 3.2943,
      "step": 2320
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.659096717834473,
      "learning_rate": 4.4174999999999996e-05,
      "loss": 3.1057,
      "step": 2330
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.213333129882812,
      "learning_rate": 4.415e-05,
      "loss": 3.0816,
      "step": 2340
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.466464042663574,
      "learning_rate": 4.4125e-05,
      "loss": 3.5256,
      "step": 2350
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.827929496765137,
      "learning_rate": 4.41e-05,
      "loss": 3.3576,
      "step": 2360
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.72918701171875,
      "learning_rate": 4.4075e-05,
      "loss": 3.3346,
      "step": 2370
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.223207473754883,
      "learning_rate": 4.405e-05,
      "loss": 3.4461,
      "step": 2380
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.741658210754395,
      "learning_rate": 4.4025e-05,
      "loss": 3.3953,
      "step": 2390
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.152872085571289,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.343,
      "step": 2400
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.376505851745605,
      "learning_rate": 4.3975e-05,
      "loss": 3.3834,
      "step": 2410
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.739089965820312,
      "learning_rate": 4.3950000000000004e-05,
      "loss": 3.3342,
      "step": 2420
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.263785362243652,
      "learning_rate": 4.3925e-05,
      "loss": 3.1568,
      "step": 2430
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.286500930786133,
      "learning_rate": 4.39e-05,
      "loss": 3.3568,
      "step": 2440
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.406773567199707,
      "learning_rate": 4.3875e-05,
      "loss": 3.2752,
      "step": 2450
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.151643753051758,
      "learning_rate": 4.385e-05,
      "loss": 3.1525,
      "step": 2460
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.31497859954834,
      "learning_rate": 4.3825e-05,
      "loss": 3.0961,
      "step": 2470
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.381696701049805,
      "learning_rate": 4.38e-05,
      "loss": 3.7949,
      "step": 2480
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.496644973754883,
      "learning_rate": 4.3775e-05,
      "loss": 3.1746,
      "step": 2490
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.095179557800293,
      "learning_rate": 4.375e-05,
      "loss": 3.3146,
      "step": 2500
    },
    {
      "epoch": 0.02,
      "eval_bleu-4": 0.03034860101959154,
      "eval_rouge-1": 30.609139999999996,
      "eval_rouge-2": 6.708258000000001,
      "eval_rouge-l": 23.538002000000006,
      "eval_runtime": 57.6441,
      "eval_samples_per_second": 0.867,
      "eval_steps_per_second": 0.069,
      "step": 2500
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.398213386535645,
      "learning_rate": 4.3725000000000006e-05,
      "loss": 3.3309,
      "step": 2510
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.879457473754883,
      "learning_rate": 4.3700000000000005e-05,
      "loss": 3.398,
      "step": 2520
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.791621208190918,
      "learning_rate": 4.3675000000000005e-05,
      "loss": 3.1748,
      "step": 2530
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.729060173034668,
      "learning_rate": 4.3650000000000004e-05,
      "loss": 3.1799,
      "step": 2540
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.294777870178223,
      "learning_rate": 4.3625e-05,
      "loss": 3.4664,
      "step": 2550
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.578865051269531,
      "learning_rate": 4.36e-05,
      "loss": 3.4385,
      "step": 2560
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.056580543518066,
      "learning_rate": 4.3575e-05,
      "loss": 3.307,
      "step": 2570
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.246904373168945,
      "learning_rate": 4.355e-05,
      "loss": 3.3648,
      "step": 2580
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.741289138793945,
      "learning_rate": 4.352500000000001e-05,
      "loss": 3.4779,
      "step": 2590
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.442605972290039,
      "learning_rate": 4.35e-05,
      "loss": 3.4859,
      "step": 2600
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.892858505249023,
      "learning_rate": 4.3475000000000006e-05,
      "loss": 3.2361,
      "step": 2610
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.032194137573242,
      "learning_rate": 4.345e-05,
      "loss": 3.2691,
      "step": 2620
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.407734870910645,
      "learning_rate": 4.3425000000000005e-05,
      "loss": 3.4699,
      "step": 2630
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.308127403259277,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 3.3676,
      "step": 2640
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.976012229919434,
      "learning_rate": 4.3375000000000004e-05,
      "loss": 3.6014,
      "step": 2650
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.854659080505371,
      "learning_rate": 4.335e-05,
      "loss": 3.3359,
      "step": 2660
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.691393852233887,
      "learning_rate": 4.3325e-05,
      "loss": 3.4312,
      "step": 2670
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.679220199584961,
      "learning_rate": 4.33e-05,
      "loss": 3.2533,
      "step": 2680
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.95842456817627,
      "learning_rate": 4.3275e-05,
      "loss": 3.4551,
      "step": 2690
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.615287780761719,
      "learning_rate": 4.325e-05,
      "loss": 3.0924,
      "step": 2700
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.031183242797852,
      "learning_rate": 4.322500000000001e-05,
      "loss": 3.024,
      "step": 2710
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.440642356872559,
      "learning_rate": 4.32e-05,
      "loss": 3.0514,
      "step": 2720
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.552197456359863,
      "learning_rate": 4.3175000000000006e-05,
      "loss": 3.2154,
      "step": 2730
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.002020835876465,
      "learning_rate": 4.315e-05,
      "loss": 3.3146,
      "step": 2740
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.149801254272461,
      "learning_rate": 4.3125000000000005e-05,
      "loss": 3.1902,
      "step": 2750
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.171662330627441,
      "learning_rate": 4.3100000000000004e-05,
      "loss": 3.3654,
      "step": 2760
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.227599143981934,
      "learning_rate": 4.3075000000000003e-05,
      "loss": 3.3301,
      "step": 2770
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.035270690917969,
      "learning_rate": 4.305e-05,
      "loss": 3.0947,
      "step": 2780
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.925765991210938,
      "learning_rate": 4.3025e-05,
      "loss": 3.3201,
      "step": 2790
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.626808166503906,
      "learning_rate": 4.3e-05,
      "loss": 3.2432,
      "step": 2800
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.118407249450684,
      "learning_rate": 4.2975e-05,
      "loss": 3.5332,
      "step": 2810
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.11931324005127,
      "learning_rate": 4.295e-05,
      "loss": 3.3826,
      "step": 2820
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.822954177856445,
      "learning_rate": 4.2925000000000007e-05,
      "loss": 3.2658,
      "step": 2830
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.685434341430664,
      "learning_rate": 4.29e-05,
      "loss": 3.1371,
      "step": 2840
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.513296127319336,
      "learning_rate": 4.2875000000000005e-05,
      "loss": 3.2744,
      "step": 2850
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.505351066589355,
      "learning_rate": 4.285e-05,
      "loss": 3.0656,
      "step": 2860
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.6592378616333,
      "learning_rate": 4.2825000000000004e-05,
      "loss": 3.7254,
      "step": 2870
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.787443161010742,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 3.4959,
      "step": 2880
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.654463768005371,
      "learning_rate": 4.2775e-05,
      "loss": 3.0506,
      "step": 2890
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.113245964050293,
      "learning_rate": 4.275e-05,
      "loss": 3.2656,
      "step": 2900
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.41266918182373,
      "learning_rate": 4.2725e-05,
      "loss": 3.2029,
      "step": 2910
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.197509765625,
      "learning_rate": 4.27e-05,
      "loss": 2.9672,
      "step": 2920
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.381295204162598,
      "learning_rate": 4.2675e-05,
      "loss": 3.6383,
      "step": 2930
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.919276237487793,
      "learning_rate": 4.265e-05,
      "loss": 3.432,
      "step": 2940
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.863398551940918,
      "learning_rate": 4.2625000000000006e-05,
      "loss": 3.3184,
      "step": 2950
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.252096176147461,
      "learning_rate": 4.26e-05,
      "loss": 3.2732,
      "step": 2960
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.105137825012207,
      "learning_rate": 4.2575000000000005e-05,
      "loss": 3.3,
      "step": 2970
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.923669815063477,
      "learning_rate": 4.2550000000000004e-05,
      "loss": 3.3014,
      "step": 2980
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.259222030639648,
      "learning_rate": 4.2525000000000004e-05,
      "loss": 3.2691,
      "step": 2990
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.341279983520508,
      "learning_rate": 4.25e-05,
      "loss": 3.1832,
      "step": 3000
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.02887643341804609,
      "eval_rouge-1": 29.869604,
      "eval_rouge-2": 6.440002,
      "eval_rouge-l": 22.168777999999996,
      "eval_runtime": 84.2922,
      "eval_samples_per_second": 0.593,
      "eval_steps_per_second": 0.047,
      "step": 3000
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.714460372924805,
      "learning_rate": 4.2475e-05,
      "loss": 3.2039,
      "step": 3010
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.811286926269531,
      "learning_rate": 4.245e-05,
      "loss": 3.1684,
      "step": 3020
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.937289237976074,
      "learning_rate": 4.2425e-05,
      "loss": 3.5678,
      "step": 3030
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.187114715576172,
      "learning_rate": 4.24e-05,
      "loss": 3.4326,
      "step": 3040
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.338300704956055,
      "learning_rate": 4.237500000000001e-05,
      "loss": 3.1988,
      "step": 3050
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.128114700317383,
      "learning_rate": 4.235e-05,
      "loss": 3.634,
      "step": 3060
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.223613739013672,
      "learning_rate": 4.2325000000000006e-05,
      "loss": 3.5029,
      "step": 3070
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.560245513916016,
      "learning_rate": 4.23e-05,
      "loss": 3.6441,
      "step": 3080
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.370487213134766,
      "learning_rate": 4.2275000000000004e-05,
      "loss": 3.3189,
      "step": 3090
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.588696479797363,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 3.4623,
      "step": 3100
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.772879600524902,
      "learning_rate": 4.2225e-05,
      "loss": 3.266,
      "step": 3110
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.75870132446289,
      "learning_rate": 4.22e-05,
      "loss": 3.2617,
      "step": 3120
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.415853500366211,
      "learning_rate": 4.2175e-05,
      "loss": 3.1922,
      "step": 3130
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.985358715057373,
      "learning_rate": 4.215e-05,
      "loss": 3.3711,
      "step": 3140
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.928120613098145,
      "learning_rate": 4.2125e-05,
      "loss": 3.1404,
      "step": 3150
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.384294509887695,
      "learning_rate": 4.21e-05,
      "loss": 3.1346,
      "step": 3160
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.526114463806152,
      "learning_rate": 4.2075000000000006e-05,
      "loss": 3.4744,
      "step": 3170
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.874114036560059,
      "learning_rate": 4.205e-05,
      "loss": 3.3717,
      "step": 3180
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.779549598693848,
      "learning_rate": 4.2025000000000005e-05,
      "loss": 3.5055,
      "step": 3190
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.359435081481934,
      "learning_rate": 4.2e-05,
      "loss": 3.3721,
      "step": 3200
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.077070236206055,
      "learning_rate": 4.1975000000000004e-05,
      "loss": 3.2734,
      "step": 3210
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.171362400054932,
      "learning_rate": 4.195e-05,
      "loss": 3.0887,
      "step": 3220
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.530020713806152,
      "learning_rate": 4.1925e-05,
      "loss": 3.0969,
      "step": 3230
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.556212425231934,
      "learning_rate": 4.19e-05,
      "loss": 3.1447,
      "step": 3240
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.882231712341309,
      "learning_rate": 4.1875e-05,
      "loss": 3.116,
      "step": 3250
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.00436782836914,
      "learning_rate": 4.185e-05,
      "loss": 3.0895,
      "step": 3260
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.798536777496338,
      "learning_rate": 4.1825e-05,
      "loss": 3.3002,
      "step": 3270
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.388670921325684,
      "learning_rate": 4.18e-05,
      "loss": 3.4289,
      "step": 3280
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.704400062561035,
      "learning_rate": 4.1775000000000006e-05,
      "loss": 3.3094,
      "step": 3290
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.59347915649414,
      "learning_rate": 4.175e-05,
      "loss": 3.2959,
      "step": 3300
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.357784271240234,
      "learning_rate": 4.1725000000000005e-05,
      "loss": 3.5039,
      "step": 3310
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.334512710571289,
      "learning_rate": 4.17e-05,
      "loss": 3.1119,
      "step": 3320
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.686197280883789,
      "learning_rate": 4.1675e-05,
      "loss": 3.0746,
      "step": 3330
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.35909366607666,
      "learning_rate": 4.165e-05,
      "loss": 3.3567,
      "step": 3340
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.980782508850098,
      "learning_rate": 4.1625e-05,
      "loss": 3.2143,
      "step": 3350
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.24488353729248,
      "learning_rate": 4.16e-05,
      "loss": 3.3822,
      "step": 3360
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.56855583190918,
      "learning_rate": 4.1575e-05,
      "loss": 3.4707,
      "step": 3370
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.92021656036377,
      "learning_rate": 4.155e-05,
      "loss": 3.3,
      "step": 3380
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.163402557373047,
      "learning_rate": 4.1525e-05,
      "loss": 3.1223,
      "step": 3390
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.364253997802734,
      "learning_rate": 4.15e-05,
      "loss": 3.5604,
      "step": 3400
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.508514404296875,
      "learning_rate": 4.1475000000000005e-05,
      "loss": 3.3535,
      "step": 3410
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.525894165039062,
      "learning_rate": 4.145e-05,
      "loss": 3.5939,
      "step": 3420
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.099784851074219,
      "learning_rate": 4.1425000000000004e-05,
      "loss": 3.359,
      "step": 3430
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.142050743103027,
      "learning_rate": 4.14e-05,
      "loss": 3.3932,
      "step": 3440
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.2601318359375,
      "learning_rate": 4.1375e-05,
      "loss": 3.3594,
      "step": 3450
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.902735710144043,
      "learning_rate": 4.135e-05,
      "loss": 3.2611,
      "step": 3460
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.682623863220215,
      "learning_rate": 4.1325e-05,
      "loss": 2.9072,
      "step": 3470
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.530282020568848,
      "learning_rate": 4.13e-05,
      "loss": 3.1941,
      "step": 3480
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.011059761047363,
      "learning_rate": 4.1275e-05,
      "loss": 3.2961,
      "step": 3490
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.621918678283691,
      "learning_rate": 4.125e-05,
      "loss": 3.3271,
      "step": 3500
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.030667519860211,
      "eval_rouge-1": 31.409178,
      "eval_rouge-2": 6.921704000000001,
      "eval_rouge-l": 23.986015999999996,
      "eval_runtime": 69.1961,
      "eval_samples_per_second": 0.723,
      "eval_steps_per_second": 0.058,
      "step": 3500
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.121627807617188,
      "learning_rate": 4.1225e-05,
      "loss": 3.4895,
      "step": 3510
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.132804870605469,
      "learning_rate": 4.12e-05,
      "loss": 3.2207,
      "step": 3520
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.175661087036133,
      "learning_rate": 4.1175000000000005e-05,
      "loss": 3.4059,
      "step": 3530
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.535951614379883,
      "learning_rate": 4.115e-05,
      "loss": 3.4219,
      "step": 3540
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.845970153808594,
      "learning_rate": 4.1125000000000004e-05,
      "loss": 3.2004,
      "step": 3550
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.359416007995605,
      "learning_rate": 4.11e-05,
      "loss": 3.2568,
      "step": 3560
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.650442123413086,
      "learning_rate": 4.1075e-05,
      "loss": 3.0807,
      "step": 3570
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.332208633422852,
      "learning_rate": 4.105e-05,
      "loss": 3.1857,
      "step": 3580
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.852630615234375,
      "learning_rate": 4.1025e-05,
      "loss": 3.0623,
      "step": 3590
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.984841346740723,
      "learning_rate": 4.1e-05,
      "loss": 3.2313,
      "step": 3600
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.864192008972168,
      "learning_rate": 4.0975e-05,
      "loss": 3.0668,
      "step": 3610
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.386452674865723,
      "learning_rate": 4.095e-05,
      "loss": 3.5816,
      "step": 3620
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.809823036193848,
      "learning_rate": 4.0925000000000005e-05,
      "loss": 3.2389,
      "step": 3630
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.004133224487305,
      "learning_rate": 4.09e-05,
      "loss": 3.3369,
      "step": 3640
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.328317642211914,
      "learning_rate": 4.0875000000000004e-05,
      "loss": 3.3871,
      "step": 3650
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.776123046875,
      "learning_rate": 4.085e-05,
      "loss": 3.0121,
      "step": 3660
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.012396812438965,
      "learning_rate": 4.0825e-05,
      "loss": 3.4684,
      "step": 3670
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.951828002929688,
      "learning_rate": 4.08e-05,
      "loss": 3.2313,
      "step": 3680
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.615015029907227,
      "learning_rate": 4.0775e-05,
      "loss": 3.4777,
      "step": 3690
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.69815731048584,
      "learning_rate": 4.075e-05,
      "loss": 3.3223,
      "step": 3700
    },
    {
      "epoch": 0.03,
      "grad_norm": 14.131495475769043,
      "learning_rate": 4.0725e-05,
      "loss": 3.1113,
      "step": 3710
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.491032600402832,
      "learning_rate": 4.07e-05,
      "loss": 3.3605,
      "step": 3720
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.335041999816895,
      "learning_rate": 4.0675e-05,
      "loss": 3.5441,
      "step": 3730
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.135517120361328,
      "learning_rate": 4.065e-05,
      "loss": 3.3725,
      "step": 3740
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.298456192016602,
      "learning_rate": 4.0625000000000005e-05,
      "loss": 3.3445,
      "step": 3750
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.40550422668457,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 3.4979,
      "step": 3760
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.921125411987305,
      "learning_rate": 4.0575000000000004e-05,
      "loss": 3.4219,
      "step": 3770
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.315868377685547,
      "learning_rate": 4.055e-05,
      "loss": 3.291,
      "step": 3780
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.174102783203125,
      "learning_rate": 4.0525e-05,
      "loss": 3.182,
      "step": 3790
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.282224655151367,
      "learning_rate": 4.05e-05,
      "loss": 3.1672,
      "step": 3800
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.503539085388184,
      "learning_rate": 4.0475e-05,
      "loss": 3.4488,
      "step": 3810
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.22955322265625,
      "learning_rate": 4.045000000000001e-05,
      "loss": 3.2428,
      "step": 3820
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.212130546569824,
      "learning_rate": 4.0425e-05,
      "loss": 3.2414,
      "step": 3830
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.016561508178711,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 3.2791,
      "step": 3840
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.357251167297363,
      "learning_rate": 4.0375e-05,
      "loss": 3.3012,
      "step": 3850
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.512429237365723,
      "learning_rate": 4.0350000000000005e-05,
      "loss": 3.4863,
      "step": 3860
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.127080917358398,
      "learning_rate": 4.0325000000000004e-05,
      "loss": 3.3996,
      "step": 3870
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.546684265136719,
      "learning_rate": 4.0300000000000004e-05,
      "loss": 3.3449,
      "step": 3880
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.678498268127441,
      "learning_rate": 4.0275e-05,
      "loss": 3.1199,
      "step": 3890
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.577620506286621,
      "learning_rate": 4.025e-05,
      "loss": 3.1162,
      "step": 3900
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.043621063232422,
      "learning_rate": 4.0225e-05,
      "loss": 3.385,
      "step": 3910
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.703389167785645,
      "learning_rate": 4.02e-05,
      "loss": 3.0832,
      "step": 3920
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.08254623413086,
      "learning_rate": 4.0175e-05,
      "loss": 3.1408,
      "step": 3930
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.075546264648438,
      "learning_rate": 4.015000000000001e-05,
      "loss": 3.3656,
      "step": 3940
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.972511291503906,
      "learning_rate": 4.0125e-05,
      "loss": 3.1109,
      "step": 3950
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.95559024810791,
      "learning_rate": 4.0100000000000006e-05,
      "loss": 3.5586,
      "step": 3960
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.562017440795898,
      "learning_rate": 4.0075e-05,
      "loss": 3.3801,
      "step": 3970
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.231368064880371,
      "learning_rate": 4.0050000000000004e-05,
      "loss": 3.192,
      "step": 3980
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.787919044494629,
      "learning_rate": 4.0025000000000004e-05,
      "loss": 3.1279,
      "step": 3990
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.45245361328125,
      "learning_rate": 4e-05,
      "loss": 3.3752,
      "step": 4000
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.028848572824570425,
      "eval_rouge-1": 31.543632000000002,
      "eval_rouge-2": 6.289822000000002,
      "eval_rouge-l": 25.01408,
      "eval_runtime": 40.2251,
      "eval_samples_per_second": 1.243,
      "eval_steps_per_second": 0.099,
      "step": 4000
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.776694297790527,
      "learning_rate": 3.9975e-05,
      "loss": 3.5295,
      "step": 4010
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.378728866577148,
      "learning_rate": 3.995e-05,
      "loss": 3.3057,
      "step": 4020
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.002074241638184,
      "learning_rate": 3.9925e-05,
      "loss": 3.1553,
      "step": 4030
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.875333786010742,
      "learning_rate": 3.99e-05,
      "loss": 3.24,
      "step": 4040
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.350680351257324,
      "learning_rate": 3.9875e-05,
      "loss": 3.1141,
      "step": 4050
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.066811561584473,
      "learning_rate": 3.9850000000000006e-05,
      "loss": 3.4035,
      "step": 4060
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.92113971710205,
      "learning_rate": 3.9825e-05,
      "loss": 3.3574,
      "step": 4070
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.684950828552246,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 3.3406,
      "step": 4080
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.692474365234375,
      "learning_rate": 3.9775e-05,
      "loss": 3.1318,
      "step": 4090
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.291885375976562,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 3.7637,
      "step": 4100
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.579084396362305,
      "learning_rate": 3.9725e-05,
      "loss": 3.4049,
      "step": 4110
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.117420196533203,
      "learning_rate": 3.97e-05,
      "loss": 3.7834,
      "step": 4120
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.014328002929688,
      "learning_rate": 3.9675e-05,
      "loss": 3.3639,
      "step": 4130
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.511417388916016,
      "learning_rate": 3.965e-05,
      "loss": 3.3131,
      "step": 4140
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.30831527709961,
      "learning_rate": 3.9625e-05,
      "loss": 3.1494,
      "step": 4150
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.010534286499023,
      "learning_rate": 3.960000000000001e-05,
      "loss": 3.2621,
      "step": 4160
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.260673522949219,
      "learning_rate": 3.9575e-05,
      "loss": 3.4018,
      "step": 4170
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.726703643798828,
      "learning_rate": 3.9550000000000006e-05,
      "loss": 3.4729,
      "step": 4180
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.921472549438477,
      "learning_rate": 3.9525e-05,
      "loss": 3.1238,
      "step": 4190
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.27306079864502,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.1072,
      "step": 4200
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.41019344329834,
      "learning_rate": 3.9475000000000004e-05,
      "loss": 3.1088,
      "step": 4210
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.60925579071045,
      "learning_rate": 3.9450000000000003e-05,
      "loss": 3.1125,
      "step": 4220
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.839221000671387,
      "learning_rate": 3.9425e-05,
      "loss": 3.2451,
      "step": 4230
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.055205345153809,
      "learning_rate": 3.94e-05,
      "loss": 3.3178,
      "step": 4240
    },
    {
      "epoch": 0.04,
      "grad_norm": 15.19128131866455,
      "learning_rate": 3.9375e-05,
      "loss": 3.3045,
      "step": 4250
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.840481758117676,
      "learning_rate": 3.935e-05,
      "loss": 3.4453,
      "step": 4260
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.532590866088867,
      "learning_rate": 3.9325e-05,
      "loss": 2.992,
      "step": 4270
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.387747764587402,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 3.1436,
      "step": 4280
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.379721641540527,
      "learning_rate": 3.9275e-05,
      "loss": 3.216,
      "step": 4290
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.853528022766113,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 3.3686,
      "step": 4300
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.23867416381836,
      "learning_rate": 3.9225e-05,
      "loss": 3.4717,
      "step": 4310
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.00219440460205,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 3.2764,
      "step": 4320
    },
    {
      "epoch": 0.04,
      "grad_norm": 14.161869049072266,
      "learning_rate": 3.9175000000000004e-05,
      "loss": 3.6609,
      "step": 4330
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.074607849121094,
      "learning_rate": 3.915e-05,
      "loss": 3.291,
      "step": 4340
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.364116668701172,
      "learning_rate": 3.9125e-05,
      "loss": 3.3871,
      "step": 4350
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.72452163696289,
      "learning_rate": 3.91e-05,
      "loss": 3.2885,
      "step": 4360
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.167083740234375,
      "learning_rate": 3.9075e-05,
      "loss": 3.3846,
      "step": 4370
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.816030502319336,
      "learning_rate": 3.905e-05,
      "loss": 3.4318,
      "step": 4380
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.103368759155273,
      "learning_rate": 3.9025e-05,
      "loss": 3.2523,
      "step": 4390
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.38350772857666,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.273,
      "step": 4400
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.808871269226074,
      "learning_rate": 3.8975e-05,
      "loss": 3.2252,
      "step": 4410
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.90772533416748,
      "learning_rate": 3.8950000000000005e-05,
      "loss": 3.1313,
      "step": 4420
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.259651184082031,
      "learning_rate": 3.8925e-05,
      "loss": 3.2256,
      "step": 4430
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.152661323547363,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 3.191,
      "step": 4440
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.96840763092041,
      "learning_rate": 3.8875e-05,
      "loss": 3.1787,
      "step": 4450
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.238696098327637,
      "learning_rate": 3.885e-05,
      "loss": 3.2669,
      "step": 4460
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.017328262329102,
      "learning_rate": 3.8825e-05,
      "loss": 3.5359,
      "step": 4470
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.820061683654785,
      "learning_rate": 3.88e-05,
      "loss": 3.583,
      "step": 4480
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.523401260375977,
      "learning_rate": 3.8775e-05,
      "loss": 3.4031,
      "step": 4490
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.179430961608887,
      "learning_rate": 3.875e-05,
      "loss": 3.0092,
      "step": 4500
    },
    {
      "epoch": 0.04,
      "eval_bleu-4": 0.03146204710914573,
      "eval_rouge-1": 31.077724000000003,
      "eval_rouge-2": 7.028196,
      "eval_rouge-l": 23.82099,
      "eval_runtime": 84.8531,
      "eval_samples_per_second": 0.589,
      "eval_steps_per_second": 0.047,
      "step": 4500
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.591140747070312,
      "learning_rate": 3.8725e-05,
      "loss": 3.4158,
      "step": 4510
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.081062316894531,
      "learning_rate": 3.8700000000000006e-05,
      "loss": 3.2713,
      "step": 4520
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.7258939743042,
      "learning_rate": 3.8675e-05,
      "loss": 3.0197,
      "step": 4530
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.807883262634277,
      "learning_rate": 3.8650000000000004e-05,
      "loss": 3.291,
      "step": 4540
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.589329719543457,
      "learning_rate": 3.8625e-05,
      "loss": 3.3012,
      "step": 4550
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.91887092590332,
      "learning_rate": 3.86e-05,
      "loss": 3.1719,
      "step": 4560
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.518806457519531,
      "learning_rate": 3.8575e-05,
      "loss": 3.2869,
      "step": 4570
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.378694534301758,
      "learning_rate": 3.855e-05,
      "loss": 3.1252,
      "step": 4580
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.570972442626953,
      "learning_rate": 3.8525e-05,
      "loss": 3.0318,
      "step": 4590
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.434893608093262,
      "learning_rate": 3.85e-05,
      "loss": 3.1967,
      "step": 4600
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.38544750213623,
      "learning_rate": 3.8475e-05,
      "loss": 3.1979,
      "step": 4610
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.401082992553711,
      "learning_rate": 3.845e-05,
      "loss": 3.327,
      "step": 4620
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.853891372680664,
      "learning_rate": 3.8425e-05,
      "loss": 3.2285,
      "step": 4630
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.920075416564941,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 3.1119,
      "step": 4640
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.431087493896484,
      "learning_rate": 3.8375e-05,
      "loss": 3.3824,
      "step": 4650
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.676177978515625,
      "learning_rate": 3.8350000000000004e-05,
      "loss": 3.2848,
      "step": 4660
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.256818771362305,
      "learning_rate": 3.8324999999999996e-05,
      "loss": 3.3508,
      "step": 4670
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.079394340515137,
      "learning_rate": 3.83e-05,
      "loss": 3.0906,
      "step": 4680
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.518827438354492,
      "learning_rate": 3.8275e-05,
      "loss": 3.2594,
      "step": 4690
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.983928680419922,
      "learning_rate": 3.825e-05,
      "loss": 3.1883,
      "step": 4700
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.101849555969238,
      "learning_rate": 3.8225e-05,
      "loss": 3.6279,
      "step": 4710
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.607260704040527,
      "learning_rate": 3.82e-05,
      "loss": 3.132,
      "step": 4720
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.75081729888916,
      "learning_rate": 3.8175e-05,
      "loss": 3.3229,
      "step": 4730
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.864459991455078,
      "learning_rate": 3.8150000000000006e-05,
      "loss": 3.2744,
      "step": 4740
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.533585548400879,
      "learning_rate": 3.8125e-05,
      "loss": 3.1088,
      "step": 4750
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.790369987487793,
      "learning_rate": 3.8100000000000005e-05,
      "loss": 3.1326,
      "step": 4760
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.246247291564941,
      "learning_rate": 3.8075e-05,
      "loss": 3.2861,
      "step": 4770
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.22367000579834,
      "learning_rate": 3.805e-05,
      "loss": 3.0713,
      "step": 4780
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.636839866638184,
      "learning_rate": 3.8025e-05,
      "loss": 3.4012,
      "step": 4790
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.106264114379883,
      "learning_rate": 3.8e-05,
      "loss": 3.3687,
      "step": 4800
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.054150581359863,
      "learning_rate": 3.7975e-05,
      "loss": 3.1113,
      "step": 4810
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.488055229187012,
      "learning_rate": 3.795e-05,
      "loss": 3.14,
      "step": 4820
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.332905769348145,
      "learning_rate": 3.7925e-05,
      "loss": 3.192,
      "step": 4830
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.947136878967285,
      "learning_rate": 3.79e-05,
      "loss": 2.8994,
      "step": 4840
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.711043357849121,
      "learning_rate": 3.7875e-05,
      "loss": 3.0861,
      "step": 4850
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.608214378356934,
      "learning_rate": 3.7850000000000005e-05,
      "loss": 3.1691,
      "step": 4860
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.239699363708496,
      "learning_rate": 3.7825e-05,
      "loss": 3.5793,
      "step": 4870
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.811654090881348,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 3.05,
      "step": 4880
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.935347080230713,
      "learning_rate": 3.7775e-05,
      "loss": 3.0359,
      "step": 4890
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.317975044250488,
      "learning_rate": 3.775e-05,
      "loss": 3.3008,
      "step": 4900
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.497422218322754,
      "learning_rate": 3.7725e-05,
      "loss": 3.44,
      "step": 4910
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.244380950927734,
      "learning_rate": 3.77e-05,
      "loss": 3.2145,
      "step": 4920
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.315733909606934,
      "learning_rate": 3.7675e-05,
      "loss": 3.4092,
      "step": 4930
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.398557662963867,
      "learning_rate": 3.765e-05,
      "loss": 3.1344,
      "step": 4940
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.855927467346191,
      "learning_rate": 3.7625e-05,
      "loss": 3.1061,
      "step": 4950
    },
    {
      "epoch": 0.04,
      "grad_norm": 15.498815536499023,
      "learning_rate": 3.76e-05,
      "loss": 3.3152,
      "step": 4960
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.41660213470459,
      "learning_rate": 3.7575e-05,
      "loss": 3.3303,
      "step": 4970
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.83072280883789,
      "learning_rate": 3.7550000000000005e-05,
      "loss": 3.4449,
      "step": 4980
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.9808349609375,
      "learning_rate": 3.7525e-05,
      "loss": 3.189,
      "step": 4990
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.777998924255371,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.1752,
      "step": 5000
    },
    {
      "epoch": 0.04,
      "eval_bleu-4": 0.02834775081970209,
      "eval_rouge-1": 31.049944,
      "eval_rouge-2": 6.670742000000001,
      "eval_rouge-l": 22.354281999999998,
      "eval_runtime": 73.395,
      "eval_samples_per_second": 0.681,
      "eval_steps_per_second": 0.054,
      "step": 5000
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.84561824798584,
      "learning_rate": 3.7475e-05,
      "loss": 3.2061,
      "step": 5010
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.457669258117676,
      "learning_rate": 3.745e-05,
      "loss": 3.1184,
      "step": 5020
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.216662406921387,
      "learning_rate": 3.7425e-05,
      "loss": 3.041,
      "step": 5030
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.305069923400879,
      "learning_rate": 3.74e-05,
      "loss": 3.2451,
      "step": 5040
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.674717903137207,
      "learning_rate": 3.737500000000001e-05,
      "loss": 3.5189,
      "step": 5050
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.76941204071045,
      "learning_rate": 3.735e-05,
      "loss": 3.1863,
      "step": 5060
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.47199535369873,
      "learning_rate": 3.7325000000000006e-05,
      "loss": 3.2023,
      "step": 5070
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.16150188446045,
      "learning_rate": 3.73e-05,
      "loss": 3.3201,
      "step": 5080
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.92195987701416,
      "learning_rate": 3.7275000000000005e-05,
      "loss": 3.3746,
      "step": 5090
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.740767478942871,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 3.0896,
      "step": 5100
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.20028305053711,
      "learning_rate": 3.7225000000000004e-05,
      "loss": 3.1795,
      "step": 5110
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.567159652709961,
      "learning_rate": 3.72e-05,
      "loss": 3.2275,
      "step": 5120
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.419992446899414,
      "learning_rate": 3.7175e-05,
      "loss": 3.2381,
      "step": 5130
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.618892669677734,
      "learning_rate": 3.715e-05,
      "loss": 3.2879,
      "step": 5140
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.864088535308838,
      "learning_rate": 3.7125e-05,
      "loss": 3.2387,
      "step": 5150
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.413002014160156,
      "learning_rate": 3.71e-05,
      "loss": 3.2498,
      "step": 5160
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.606770515441895,
      "learning_rate": 3.707500000000001e-05,
      "loss": 3.535,
      "step": 5170
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.936239242553711,
      "learning_rate": 3.705e-05,
      "loss": 3.2699,
      "step": 5180
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.684239387512207,
      "learning_rate": 3.7025000000000005e-05,
      "loss": 3.2033,
      "step": 5190
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.708818435668945,
      "learning_rate": 3.7e-05,
      "loss": 3.3016,
      "step": 5200
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.774689674377441,
      "learning_rate": 3.6975000000000004e-05,
      "loss": 3.3326,
      "step": 5210
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.549942970275879,
      "learning_rate": 3.6950000000000004e-05,
      "loss": 3.5652,
      "step": 5220
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.170089721679688,
      "learning_rate": 3.6925e-05,
      "loss": 3.2639,
      "step": 5230
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.821866035461426,
      "learning_rate": 3.69e-05,
      "loss": 3.1221,
      "step": 5240
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.241917610168457,
      "learning_rate": 3.6875e-05,
      "loss": 3.515,
      "step": 5250
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.631979942321777,
      "learning_rate": 3.685e-05,
      "loss": 3.1627,
      "step": 5260
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.870097637176514,
      "learning_rate": 3.6825e-05,
      "loss": 3.3361,
      "step": 5270
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.592941284179688,
      "learning_rate": 3.68e-05,
      "loss": 3.3475,
      "step": 5280
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.291369438171387,
      "learning_rate": 3.6775000000000006e-05,
      "loss": 3.2678,
      "step": 5290
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.715483665466309,
      "learning_rate": 3.675e-05,
      "loss": 3.3059,
      "step": 5300
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.784893035888672,
      "learning_rate": 3.6725000000000005e-05,
      "loss": 3.2912,
      "step": 5310
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.250903129577637,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 3.2039,
      "step": 5320
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.697293281555176,
      "learning_rate": 3.6675000000000004e-05,
      "loss": 3.0924,
      "step": 5330
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.06985855102539,
      "learning_rate": 3.665e-05,
      "loss": 3.1422,
      "step": 5340
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.851428031921387,
      "learning_rate": 3.6625e-05,
      "loss": 3.1443,
      "step": 5350
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.224361419677734,
      "learning_rate": 3.66e-05,
      "loss": 3.3092,
      "step": 5360
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.102925300598145,
      "learning_rate": 3.6575e-05,
      "loss": 3.1781,
      "step": 5370
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.71729850769043,
      "learning_rate": 3.655e-05,
      "loss": 3.108,
      "step": 5380
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.646256446838379,
      "learning_rate": 3.652500000000001e-05,
      "loss": 3.2619,
      "step": 5390
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.442869186401367,
      "learning_rate": 3.65e-05,
      "loss": 3.2205,
      "step": 5400
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.407305717468262,
      "learning_rate": 3.6475000000000006e-05,
      "loss": 3.0176,
      "step": 5410
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.310140609741211,
      "learning_rate": 3.645e-05,
      "loss": 3.1242,
      "step": 5420
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.893707275390625,
      "learning_rate": 3.6425000000000004e-05,
      "loss": 3.2094,
      "step": 5430
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.411767959594727,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 3.3332,
      "step": 5440
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.516278266906738,
      "learning_rate": 3.6375e-05,
      "loss": 3.4721,
      "step": 5450
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.886275291442871,
      "learning_rate": 3.635e-05,
      "loss": 3.4145,
      "step": 5460
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.521522521972656,
      "learning_rate": 3.6325e-05,
      "loss": 3.1502,
      "step": 5470
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.296154022216797,
      "learning_rate": 3.63e-05,
      "loss": 3.4711,
      "step": 5480
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.149287223815918,
      "learning_rate": 3.6275e-05,
      "loss": 3.233,
      "step": 5490
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.439455032348633,
      "learning_rate": 3.625e-05,
      "loss": 3.2061,
      "step": 5500
    },
    {
      "epoch": 0.05,
      "eval_bleu-4": 0.03279551257108684,
      "eval_rouge-1": 32.382618,
      "eval_rouge-2": 7.359508000000001,
      "eval_rouge-l": 25.228258,
      "eval_runtime": 52.6967,
      "eval_samples_per_second": 0.949,
      "eval_steps_per_second": 0.076,
      "step": 5500
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.546496391296387,
      "learning_rate": 3.6225000000000006e-05,
      "loss": 3.1598,
      "step": 5510
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.116765022277832,
      "learning_rate": 3.62e-05,
      "loss": 3.3828,
      "step": 5520
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.935365200042725,
      "learning_rate": 3.6175000000000005e-05,
      "loss": 3.4996,
      "step": 5530
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.16452407836914,
      "learning_rate": 3.615e-05,
      "loss": 3.0773,
      "step": 5540
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.96005630493164,
      "learning_rate": 3.6125000000000004e-05,
      "loss": 3.4582,
      "step": 5550
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.650351524353027,
      "learning_rate": 3.61e-05,
      "loss": 2.9195,
      "step": 5560
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.22922420501709,
      "learning_rate": 3.6075e-05,
      "loss": 3.1598,
      "step": 5570
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.46432113647461,
      "learning_rate": 3.605e-05,
      "loss": 3.4293,
      "step": 5580
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.957307815551758,
      "learning_rate": 3.6025e-05,
      "loss": 3.2867,
      "step": 5590
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.201791763305664,
      "learning_rate": 3.6e-05,
      "loss": 3.1455,
      "step": 5600
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.038151741027832,
      "learning_rate": 3.5975e-05,
      "loss": 3.2496,
      "step": 5610
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.438831329345703,
      "learning_rate": 3.595e-05,
      "loss": 3.0619,
      "step": 5620
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.072809219360352,
      "learning_rate": 3.5925000000000006e-05,
      "loss": 3.1066,
      "step": 5630
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.81936264038086,
      "learning_rate": 3.59e-05,
      "loss": 3.2885,
      "step": 5640
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.40576457977295,
      "learning_rate": 3.5875000000000005e-05,
      "loss": 3.1742,
      "step": 5650
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.968134880065918,
      "learning_rate": 3.585e-05,
      "loss": 3.1451,
      "step": 5660
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.72863483428955,
      "learning_rate": 3.5825000000000003e-05,
      "loss": 3.0118,
      "step": 5670
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.83395004272461,
      "learning_rate": 3.58e-05,
      "loss": 3.1896,
      "step": 5680
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.458921432495117,
      "learning_rate": 3.5775e-05,
      "loss": 3.3129,
      "step": 5690
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.873562812805176,
      "learning_rate": 3.575e-05,
      "loss": 3.1516,
      "step": 5700
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.766197204589844,
      "learning_rate": 3.5725e-05,
      "loss": 3.2904,
      "step": 5710
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.522059440612793,
      "learning_rate": 3.57e-05,
      "loss": 3.2789,
      "step": 5720
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.028907775878906,
      "learning_rate": 3.5675e-05,
      "loss": 3.2674,
      "step": 5730
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.39172649383545,
      "learning_rate": 3.565e-05,
      "loss": 3.1887,
      "step": 5740
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.279144287109375,
      "learning_rate": 3.5625000000000005e-05,
      "loss": 3.4121,
      "step": 5750
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.349796295166016,
      "learning_rate": 3.56e-05,
      "loss": 3.0057,
      "step": 5760
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.090788841247559,
      "learning_rate": 3.5575000000000004e-05,
      "loss": 3.0979,
      "step": 5770
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.609777450561523,
      "learning_rate": 3.555e-05,
      "loss": 3.2811,
      "step": 5780
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.716591835021973,
      "learning_rate": 3.5525e-05,
      "loss": 2.8288,
      "step": 5790
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.49222469329834,
      "learning_rate": 3.55e-05,
      "loss": 3.2676,
      "step": 5800
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.228135108947754,
      "learning_rate": 3.5475e-05,
      "loss": 3.1596,
      "step": 5810
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.339402198791504,
      "learning_rate": 3.545e-05,
      "loss": 3.3545,
      "step": 5820
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.91162109375,
      "learning_rate": 3.5425e-05,
      "loss": 3.2092,
      "step": 5830
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.063432693481445,
      "learning_rate": 3.54e-05,
      "loss": 3.3896,
      "step": 5840
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.950145721435547,
      "learning_rate": 3.5375e-05,
      "loss": 3.385,
      "step": 5850
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.869710922241211,
      "learning_rate": 3.535e-05,
      "loss": 3.349,
      "step": 5860
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.614736557006836,
      "learning_rate": 3.5325000000000005e-05,
      "loss": 3.365,
      "step": 5870
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.726547241210938,
      "learning_rate": 3.53e-05,
      "loss": 3.1545,
      "step": 5880
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.196733474731445,
      "learning_rate": 3.5275000000000004e-05,
      "loss": 2.8865,
      "step": 5890
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.601470947265625,
      "learning_rate": 3.525e-05,
      "loss": 3.4893,
      "step": 5900
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.62226676940918,
      "learning_rate": 3.5225e-05,
      "loss": 3.1119,
      "step": 5910
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.806347370147705,
      "learning_rate": 3.52e-05,
      "loss": 3.2521,
      "step": 5920
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.582616806030273,
      "learning_rate": 3.5175e-05,
      "loss": 3.3264,
      "step": 5930
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.650069236755371,
      "learning_rate": 3.515e-05,
      "loss": 3.359,
      "step": 5940
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.856364250183105,
      "learning_rate": 3.5125e-05,
      "loss": 3.2092,
      "step": 5950
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.651578903198242,
      "learning_rate": 3.51e-05,
      "loss": 3.326,
      "step": 5960
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.775851249694824,
      "learning_rate": 3.5075000000000006e-05,
      "loss": 3.1906,
      "step": 5970
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.597359657287598,
      "learning_rate": 3.505e-05,
      "loss": 3.3768,
      "step": 5980
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.04328441619873,
      "learning_rate": 3.5025000000000004e-05,
      "loss": 3.1775,
      "step": 5990
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.18796157836914,
      "learning_rate": 3.5e-05,
      "loss": 3.4004,
      "step": 6000
    },
    {
      "epoch": 0.05,
      "eval_bleu-4": 0.036632537968234576,
      "eval_rouge-1": 32.142292000000005,
      "eval_rouge-2": 6.67454,
      "eval_rouge-l": 25.423346000000002,
      "eval_runtime": 30.5415,
      "eval_samples_per_second": 1.637,
      "eval_steps_per_second": 0.131,
      "step": 6000
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.058512687683105,
      "learning_rate": 3.4975e-05,
      "loss": 3.1518,
      "step": 6010
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.962569236755371,
      "learning_rate": 3.495e-05,
      "loss": 3.2398,
      "step": 6020
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.671311378479004,
      "learning_rate": 3.4925e-05,
      "loss": 3.202,
      "step": 6030
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.535064697265625,
      "learning_rate": 3.49e-05,
      "loss": 3.2031,
      "step": 6040
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.440774917602539,
      "learning_rate": 3.4875e-05,
      "loss": 3.0943,
      "step": 6050
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.131446838378906,
      "learning_rate": 3.485e-05,
      "loss": 3.1295,
      "step": 6060
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.72753620147705,
      "learning_rate": 3.4825e-05,
      "loss": 3.352,
      "step": 6070
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.13767147064209,
      "learning_rate": 3.48e-05,
      "loss": 3.3107,
      "step": 6080
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.982434272766113,
      "learning_rate": 3.4775000000000005e-05,
      "loss": 3.3377,
      "step": 6090
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.180349349975586,
      "learning_rate": 3.475e-05,
      "loss": 3.2994,
      "step": 6100
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.041205406188965,
      "learning_rate": 3.4725000000000004e-05,
      "loss": 3.3406,
      "step": 6110
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.179863929748535,
      "learning_rate": 3.4699999999999996e-05,
      "loss": 3.1797,
      "step": 6120
    },
    {
      "epoch": 0.05,
      "grad_norm": 15.899177551269531,
      "learning_rate": 3.4675e-05,
      "loss": 3.2443,
      "step": 6130
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.445298194885254,
      "learning_rate": 3.465e-05,
      "loss": 3.0736,
      "step": 6140
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.74213981628418,
      "learning_rate": 3.4625e-05,
      "loss": 3.4328,
      "step": 6150
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.020593643188477,
      "learning_rate": 3.46e-05,
      "loss": 3.1912,
      "step": 6160
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.038007736206055,
      "learning_rate": 3.4575e-05,
      "loss": 3.4604,
      "step": 6170
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.325918197631836,
      "learning_rate": 3.455e-05,
      "loss": 3.3994,
      "step": 6180
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.685043334960938,
      "learning_rate": 3.4525e-05,
      "loss": 3.1248,
      "step": 6190
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.086628913879395,
      "learning_rate": 3.45e-05,
      "loss": 3.4131,
      "step": 6200
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.55848503112793,
      "learning_rate": 3.4475000000000005e-05,
      "loss": 3.2656,
      "step": 6210
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.952846527099609,
      "learning_rate": 3.445e-05,
      "loss": 3.0195,
      "step": 6220
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.530394554138184,
      "learning_rate": 3.4425e-05,
      "loss": 3.4186,
      "step": 6230
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.602360725402832,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 3.2932,
      "step": 6240
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.863875389099121,
      "learning_rate": 3.4375e-05,
      "loss": 3.2211,
      "step": 6250
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.219677925109863,
      "learning_rate": 3.435e-05,
      "loss": 3.3037,
      "step": 6260
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.564455032348633,
      "learning_rate": 3.4325e-05,
      "loss": 3.4822,
      "step": 6270
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.51793098449707,
      "learning_rate": 3.430000000000001e-05,
      "loss": 3.2859,
      "step": 6280
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.724491119384766,
      "learning_rate": 3.4275e-05,
      "loss": 3.0641,
      "step": 6290
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.658498764038086,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 3.1963,
      "step": 6300
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.773419380187988,
      "learning_rate": 3.4225e-05,
      "loss": 3.3494,
      "step": 6310
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.946178436279297,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 3.567,
      "step": 6320
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.900548934936523,
      "learning_rate": 3.4175000000000004e-05,
      "loss": 3.4494,
      "step": 6330
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.541189193725586,
      "learning_rate": 3.415e-05,
      "loss": 3.2795,
      "step": 6340
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.446577072143555,
      "learning_rate": 3.4125e-05,
      "loss": 3.3617,
      "step": 6350
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.969188690185547,
      "learning_rate": 3.41e-05,
      "loss": 3.1953,
      "step": 6360
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.2839937210083,
      "learning_rate": 3.4075e-05,
      "loss": 3.4148,
      "step": 6370
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.287768363952637,
      "learning_rate": 3.405e-05,
      "loss": 3.1752,
      "step": 6380
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.509568214416504,
      "learning_rate": 3.4025e-05,
      "loss": 3.2725,
      "step": 6390
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.037308692932129,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.1301,
      "step": 6400
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.47184944152832,
      "learning_rate": 3.3975e-05,
      "loss": 3.1934,
      "step": 6410
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.978865623474121,
      "learning_rate": 3.3950000000000005e-05,
      "loss": 3.335,
      "step": 6420
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.80695629119873,
      "learning_rate": 3.3925e-05,
      "loss": 3.2516,
      "step": 6430
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.913841247558594,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 3.1686,
      "step": 6440
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.446879386901855,
      "learning_rate": 3.3875000000000003e-05,
      "loss": 3.2316,
      "step": 6450
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.515241622924805,
      "learning_rate": 3.385e-05,
      "loss": 3.3539,
      "step": 6460
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.118327140808105,
      "learning_rate": 3.3825e-05,
      "loss": 3.2895,
      "step": 6470
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.93216323852539,
      "learning_rate": 3.38e-05,
      "loss": 3.0314,
      "step": 6480
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.363277435302734,
      "learning_rate": 3.3775e-05,
      "loss": 3.4006,
      "step": 6490
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.515378952026367,
      "learning_rate": 3.375000000000001e-05,
      "loss": 3.2252,
      "step": 6500
    },
    {
      "epoch": 0.06,
      "eval_bleu-4": 0.033523603390713974,
      "eval_rouge-1": 31.877150000000007,
      "eval_rouge-2": 6.930996000000001,
      "eval_rouge-l": 23.978305999999996,
      "eval_runtime": 60.2982,
      "eval_samples_per_second": 0.829,
      "eval_steps_per_second": 0.066,
      "step": 6500
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.112661361694336,
      "learning_rate": 3.3725e-05,
      "loss": 3.3842,
      "step": 6510
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.249979019165039,
      "learning_rate": 3.3700000000000006e-05,
      "loss": 3.2246,
      "step": 6520
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.340788841247559,
      "learning_rate": 3.3675e-05,
      "loss": 3.1852,
      "step": 6530
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.760784149169922,
      "learning_rate": 3.3650000000000005e-05,
      "loss": 2.9445,
      "step": 6540
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.795919418334961,
      "learning_rate": 3.3625000000000004e-05,
      "loss": 3.1729,
      "step": 6550
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.437540054321289,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 3.3705,
      "step": 6560
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.823237419128418,
      "learning_rate": 3.3575e-05,
      "loss": 3.1279,
      "step": 6570
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.817033767700195,
      "learning_rate": 3.355e-05,
      "loss": 3.5453,
      "step": 6580
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.934394836425781,
      "learning_rate": 3.3525e-05,
      "loss": 3.1879,
      "step": 6590
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.406896114349365,
      "learning_rate": 3.35e-05,
      "loss": 3.1109,
      "step": 6600
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.223538398742676,
      "learning_rate": 3.3475e-05,
      "loss": 3.3842,
      "step": 6610
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.88717269897461,
      "learning_rate": 3.345000000000001e-05,
      "loss": 3.1973,
      "step": 6620
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.364523887634277,
      "learning_rate": 3.3425e-05,
      "loss": 2.9977,
      "step": 6630
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.923267364501953,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 3.0898,
      "step": 6640
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.222710609436035,
      "learning_rate": 3.3375e-05,
      "loss": 3.5795,
      "step": 6650
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.692519187927246,
      "learning_rate": 3.3350000000000004e-05,
      "loss": 3.2201,
      "step": 6660
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.748305320739746,
      "learning_rate": 3.3325000000000004e-05,
      "loss": 3.2361,
      "step": 6670
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.924612998962402,
      "learning_rate": 3.33e-05,
      "loss": 3.1695,
      "step": 6680
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.632829666137695,
      "learning_rate": 3.3275e-05,
      "loss": 3.2355,
      "step": 6690
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.211156845092773,
      "learning_rate": 3.325e-05,
      "loss": 3.2244,
      "step": 6700
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.776430130004883,
      "learning_rate": 3.3225e-05,
      "loss": 3.0071,
      "step": 6710
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.903869152069092,
      "learning_rate": 3.32e-05,
      "loss": 3.2287,
      "step": 6720
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.521506309509277,
      "learning_rate": 3.3175e-05,
      "loss": 3.177,
      "step": 6730
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.247326850891113,
      "learning_rate": 3.3150000000000006e-05,
      "loss": 3.2131,
      "step": 6740
    },
    {
      "epoch": 0.06,
      "grad_norm": 14.686806678771973,
      "learning_rate": 3.3125e-05,
      "loss": 3.2523,
      "step": 6750
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.939236640930176,
      "learning_rate": 3.3100000000000005e-05,
      "loss": 3.1848,
      "step": 6760
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.86862850189209,
      "learning_rate": 3.3075e-05,
      "loss": 3.4729,
      "step": 6770
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.05113410949707,
      "learning_rate": 3.3050000000000004e-05,
      "loss": 3.3637,
      "step": 6780
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.096193790435791,
      "learning_rate": 3.3025e-05,
      "loss": 3.3205,
      "step": 6790
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.239948272705078,
      "learning_rate": 3.3e-05,
      "loss": 3.2955,
      "step": 6800
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.068277359008789,
      "learning_rate": 3.2975e-05,
      "loss": 3.608,
      "step": 6810
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.552251815795898,
      "learning_rate": 3.295e-05,
      "loss": 3.365,
      "step": 6820
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.819459915161133,
      "learning_rate": 3.2925e-05,
      "loss": 3.0648,
      "step": 6830
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.823829174041748,
      "learning_rate": 3.29e-05,
      "loss": 3.2484,
      "step": 6840
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.014656066894531,
      "learning_rate": 3.2875e-05,
      "loss": 3.2578,
      "step": 6850
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.195860862731934,
      "learning_rate": 3.2850000000000006e-05,
      "loss": 3.3488,
      "step": 6860
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.4359049797058105,
      "learning_rate": 3.2825e-05,
      "loss": 3.1832,
      "step": 6870
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.065704345703125,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 3.4479,
      "step": 6880
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.208499908447266,
      "learning_rate": 3.2775e-05,
      "loss": 3.3098,
      "step": 6890
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.726773262023926,
      "learning_rate": 3.275e-05,
      "loss": 3.1229,
      "step": 6900
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.691262245178223,
      "learning_rate": 3.2725e-05,
      "loss": 3.4449,
      "step": 6910
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.976624488830566,
      "learning_rate": 3.27e-05,
      "loss": 3.1449,
      "step": 6920
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.304598808288574,
      "learning_rate": 3.2675e-05,
      "loss": 3.3473,
      "step": 6930
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.220736503601074,
      "learning_rate": 3.265e-05,
      "loss": 3.2258,
      "step": 6940
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.509467124938965,
      "learning_rate": 3.2625e-05,
      "loss": 3.132,
      "step": 6950
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.675788879394531,
      "learning_rate": 3.26e-05,
      "loss": 3.2883,
      "step": 6960
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.349082946777344,
      "learning_rate": 3.2575e-05,
      "loss": 3.3449,
      "step": 6970
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.642879486083984,
      "learning_rate": 3.2550000000000005e-05,
      "loss": 3.2439,
      "step": 6980
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.089763641357422,
      "learning_rate": 3.2525e-05,
      "loss": 3.5072,
      "step": 6990
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.645666122436523,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.1275,
      "step": 7000
    },
    {
      "epoch": 0.06,
      "eval_bleu-4": 0.03574014105864612,
      "eval_rouge-1": 31.635223999999994,
      "eval_rouge-2": 7.007278,
      "eval_rouge-l": 24.09556,
      "eval_runtime": 58.2283,
      "eval_samples_per_second": 0.859,
      "eval_steps_per_second": 0.069,
      "step": 7000
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.2274169921875,
      "learning_rate": 3.2474999999999997e-05,
      "loss": 3.3314,
      "step": 7010
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.633740425109863,
      "learning_rate": 3.245e-05,
      "loss": 3.3131,
      "step": 7020
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.597018241882324,
      "learning_rate": 3.2425e-05,
      "loss": 3.3096,
      "step": 7030
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.202420234680176,
      "learning_rate": 3.24e-05,
      "loss": 3.2459,
      "step": 7040
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.50711441040039,
      "learning_rate": 3.2375e-05,
      "loss": 3.0775,
      "step": 7050
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.199152946472168,
      "learning_rate": 3.235e-05,
      "loss": 3.2066,
      "step": 7060
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.121870040893555,
      "learning_rate": 3.2325e-05,
      "loss": 3.3801,
      "step": 7070
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.285977363586426,
      "learning_rate": 3.2300000000000006e-05,
      "loss": 3.1484,
      "step": 7080
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.655365943908691,
      "learning_rate": 3.2275e-05,
      "loss": 3.2193,
      "step": 7090
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.38502025604248,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 3.1479,
      "step": 7100
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.516984939575195,
      "learning_rate": 3.2225e-05,
      "loss": 3.2523,
      "step": 7110
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.966909408569336,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 3.1664,
      "step": 7120
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.407049179077148,
      "learning_rate": 3.2175e-05,
      "loss": 3.119,
      "step": 7130
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.873557090759277,
      "learning_rate": 3.215e-05,
      "loss": 3.3152,
      "step": 7140
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.689170837402344,
      "learning_rate": 3.2125e-05,
      "loss": 3.1199,
      "step": 7150
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.587677001953125,
      "learning_rate": 3.21e-05,
      "loss": 3.3639,
      "step": 7160
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.509210586547852,
      "learning_rate": 3.2075e-05,
      "loss": 3.323,
      "step": 7170
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.031301498413086,
      "learning_rate": 3.205e-05,
      "loss": 3.1771,
      "step": 7180
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.063774108886719,
      "learning_rate": 3.2025e-05,
      "loss": 2.9699,
      "step": 7190
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.797968864440918,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.3352,
      "step": 7200
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.849590301513672,
      "learning_rate": 3.1975e-05,
      "loss": 3.5301,
      "step": 7210
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.993144989013672,
      "learning_rate": 3.1950000000000004e-05,
      "loss": 3.1887,
      "step": 7220
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.666385650634766,
      "learning_rate": 3.1925e-05,
      "loss": 3.2115,
      "step": 7230
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.851883888244629,
      "learning_rate": 3.19e-05,
      "loss": 2.9266,
      "step": 7240
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.986398696899414,
      "learning_rate": 3.1875e-05,
      "loss": 3.1168,
      "step": 7250
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.71863079071045,
      "learning_rate": 3.185e-05,
      "loss": 3.1471,
      "step": 7260
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.914965629577637,
      "learning_rate": 3.1825e-05,
      "loss": 3.3584,
      "step": 7270
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.110304832458496,
      "learning_rate": 3.18e-05,
      "loss": 3.2084,
      "step": 7280
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.452995300292969,
      "learning_rate": 3.1775e-05,
      "loss": 3.4434,
      "step": 7290
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.255172729492188,
      "learning_rate": 3.175e-05,
      "loss": 3.1756,
      "step": 7300
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.141575813293457,
      "learning_rate": 3.1725e-05,
      "loss": 3.5914,
      "step": 7310
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.594428062438965,
      "learning_rate": 3.1700000000000005e-05,
      "loss": 3.4893,
      "step": 7320
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.546298027038574,
      "learning_rate": 3.1675e-05,
      "loss": 3.1148,
      "step": 7330
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.82651424407959,
      "learning_rate": 3.1650000000000004e-05,
      "loss": 3.0643,
      "step": 7340
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.021382331848145,
      "learning_rate": 3.1624999999999996e-05,
      "loss": 3.2973,
      "step": 7350
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.98231029510498,
      "learning_rate": 3.16e-05,
      "loss": 3.2684,
      "step": 7360
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.907035827636719,
      "learning_rate": 3.1575e-05,
      "loss": 3.152,
      "step": 7370
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.035026550292969,
      "learning_rate": 3.155e-05,
      "loss": 2.9906,
      "step": 7380
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.088299751281738,
      "learning_rate": 3.1525e-05,
      "loss": 3.5268,
      "step": 7390
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.71065616607666,
      "learning_rate": 3.15e-05,
      "loss": 3.5635,
      "step": 7400
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.934889793395996,
      "learning_rate": 3.1475e-05,
      "loss": 3.3533,
      "step": 7410
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.385651588439941,
      "learning_rate": 3.145e-05,
      "loss": 3.0658,
      "step": 7420
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.292013168334961,
      "learning_rate": 3.1425e-05,
      "loss": 3.2506,
      "step": 7430
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.710410118103027,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 3.2109,
      "step": 7440
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.854533195495605,
      "learning_rate": 3.1375e-05,
      "loss": 3.309,
      "step": 7450
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.25755786895752,
      "learning_rate": 3.135e-05,
      "loss": 3.0775,
      "step": 7460
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.131854057312012,
      "learning_rate": 3.1324999999999996e-05,
      "loss": 3.0541,
      "step": 7470
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.08701229095459,
      "learning_rate": 3.13e-05,
      "loss": 3.224,
      "step": 7480
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.071440696716309,
      "learning_rate": 3.1275e-05,
      "loss": 3.0998,
      "step": 7490
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.971714973449707,
      "learning_rate": 3.125e-05,
      "loss": 3.0395,
      "step": 7500
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.031686031481796946,
      "eval_rouge-1": 32.824861999999996,
      "eval_rouge-2": 7.208184,
      "eval_rouge-l": 24.645875999999998,
      "eval_runtime": 57.6174,
      "eval_samples_per_second": 0.868,
      "eval_steps_per_second": 0.069,
      "step": 7500
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.251689910888672,
      "learning_rate": 3.122500000000001e-05,
      "loss": 3.4062,
      "step": 7510
    },
    {
      "epoch": 0.07,
      "grad_norm": 17.251964569091797,
      "learning_rate": 3.12e-05,
      "loss": 3.0744,
      "step": 7520
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.027362823486328,
      "learning_rate": 3.1175000000000006e-05,
      "loss": 3.2926,
      "step": 7530
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.379523277282715,
      "learning_rate": 3.115e-05,
      "loss": 3.2658,
      "step": 7540
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.053565979003906,
      "learning_rate": 3.1125000000000004e-05,
      "loss": 3.3697,
      "step": 7550
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.134276390075684,
      "learning_rate": 3.1100000000000004e-05,
      "loss": 3.0963,
      "step": 7560
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.427447319030762,
      "learning_rate": 3.1075e-05,
      "loss": 3.3811,
      "step": 7570
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.258707046508789,
      "learning_rate": 3.105e-05,
      "loss": 3.1207,
      "step": 7580
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.390382766723633,
      "learning_rate": 3.1025e-05,
      "loss": 3.2318,
      "step": 7590
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.793813705444336,
      "learning_rate": 3.1e-05,
      "loss": 3.173,
      "step": 7600
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.369482040405273,
      "learning_rate": 3.0975e-05,
      "loss": 3.1545,
      "step": 7610
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.978779792785645,
      "learning_rate": 3.095e-05,
      "loss": 3.3475,
      "step": 7620
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.529438018798828,
      "learning_rate": 3.0925000000000006e-05,
      "loss": 3.1973,
      "step": 7630
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.07675552368164,
      "learning_rate": 3.09e-05,
      "loss": 3.2879,
      "step": 7640
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.381775856018066,
      "learning_rate": 3.0875000000000005e-05,
      "loss": 3.24,
      "step": 7650
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.15927791595459,
      "learning_rate": 3.0850000000000004e-05,
      "loss": 3.4293,
      "step": 7660
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.299449920654297,
      "learning_rate": 3.0825000000000004e-05,
      "loss": 3.4744,
      "step": 7670
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.082991600036621,
      "learning_rate": 3.08e-05,
      "loss": 3.2715,
      "step": 7680
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.130910873413086,
      "learning_rate": 3.0775e-05,
      "loss": 2.9293,
      "step": 7690
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.793549537658691,
      "learning_rate": 3.075e-05,
      "loss": 3.0508,
      "step": 7700
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.068997383117676,
      "learning_rate": 3.0725e-05,
      "loss": 3.1867,
      "step": 7710
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.951539516448975,
      "learning_rate": 3.07e-05,
      "loss": 3.3832,
      "step": 7720
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.883265495300293,
      "learning_rate": 3.067500000000001e-05,
      "loss": 3.315,
      "step": 7730
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.067512512207031,
      "learning_rate": 3.065e-05,
      "loss": 3.3869,
      "step": 7740
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.656811714172363,
      "learning_rate": 3.0625000000000006e-05,
      "loss": 3.368,
      "step": 7750
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.27829360961914,
      "learning_rate": 3.06e-05,
      "loss": 3.2982,
      "step": 7760
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.040942192077637,
      "learning_rate": 3.0575000000000005e-05,
      "loss": 3.3143,
      "step": 7770
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.196598052978516,
      "learning_rate": 3.0550000000000004e-05,
      "loss": 3.1056,
      "step": 7780
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.797680854797363,
      "learning_rate": 3.0525e-05,
      "loss": 3.2559,
      "step": 7790
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.906538963317871,
      "learning_rate": 3.05e-05,
      "loss": 3.1172,
      "step": 7800
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.375773429870605,
      "learning_rate": 3.0475000000000002e-05,
      "loss": 2.9993,
      "step": 7810
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.926056861877441,
      "learning_rate": 3.045e-05,
      "loss": 3.1576,
      "step": 7820
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.124306678771973,
      "learning_rate": 3.0425000000000004e-05,
      "loss": 3.3871,
      "step": 7830
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.790947914123535,
      "learning_rate": 3.04e-05,
      "loss": 3.0367,
      "step": 7840
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.69966983795166,
      "learning_rate": 3.0375000000000003e-05,
      "loss": 3.1236,
      "step": 7850
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.6245698928833,
      "learning_rate": 3.035e-05,
      "loss": 3.1744,
      "step": 7860
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.564129829406738,
      "learning_rate": 3.0325000000000002e-05,
      "loss": 3.3168,
      "step": 7870
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.24500560760498,
      "learning_rate": 3.03e-05,
      "loss": 3.3215,
      "step": 7880
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.359789848327637,
      "learning_rate": 3.0275000000000004e-05,
      "loss": 3.0992,
      "step": 7890
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.897666931152344,
      "learning_rate": 3.025e-05,
      "loss": 2.8266,
      "step": 7900
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.376751899719238,
      "learning_rate": 3.0225000000000003e-05,
      "loss": 3.2119,
      "step": 7910
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.704905033111572,
      "learning_rate": 3.02e-05,
      "loss": 3.1682,
      "step": 7920
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.577567100524902,
      "learning_rate": 3.0175e-05,
      "loss": 3.4537,
      "step": 7930
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.845388412475586,
      "learning_rate": 3.015e-05,
      "loss": 3.1752,
      "step": 7940
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.565311431884766,
      "learning_rate": 3.0125000000000004e-05,
      "loss": 3.1867,
      "step": 7950
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.192994117736816,
      "learning_rate": 3.01e-05,
      "loss": 3.1846,
      "step": 7960
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.713757514953613,
      "learning_rate": 3.0075000000000003e-05,
      "loss": 3.1699,
      "step": 7970
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.341706275939941,
      "learning_rate": 3.0050000000000002e-05,
      "loss": 3.2535,
      "step": 7980
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.28247356414795,
      "learning_rate": 3.0025000000000005e-05,
      "loss": 3.4045,
      "step": 7990
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.366976737976074,
      "learning_rate": 3e-05,
      "loss": 3.3449,
      "step": 8000
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.034267448478647385,
      "eval_rouge-1": 31.579323999999996,
      "eval_rouge-2": 7.014500000000001,
      "eval_rouge-l": 24.714802,
      "eval_runtime": 56.6407,
      "eval_samples_per_second": 0.883,
      "eval_steps_per_second": 0.071,
      "step": 8000
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.726783752441406,
      "learning_rate": 2.9975000000000004e-05,
      "loss": 3.4957,
      "step": 8010
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.067195892333984,
      "learning_rate": 2.995e-05,
      "loss": 3.1287,
      "step": 8020
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.171943664550781,
      "learning_rate": 2.9925000000000002e-05,
      "loss": 3.173,
      "step": 8030
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.253782272338867,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 3.2816,
      "step": 8040
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.439741134643555,
      "learning_rate": 2.9875000000000004e-05,
      "loss": 3.4566,
      "step": 8050
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.530073165893555,
      "learning_rate": 2.985e-05,
      "loss": 3.3357,
      "step": 8060
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.409798622131348,
      "learning_rate": 2.9825000000000003e-05,
      "loss": 3.1955,
      "step": 8070
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.12090015411377,
      "learning_rate": 2.98e-05,
      "loss": 3.3682,
      "step": 8080
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.566841125488281,
      "learning_rate": 2.9775000000000002e-05,
      "loss": 3.3998,
      "step": 8090
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.51885986328125,
      "learning_rate": 2.975e-05,
      "loss": 3.4256,
      "step": 8100
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.918136596679688,
      "learning_rate": 2.9725000000000004e-05,
      "loss": 3.3533,
      "step": 8110
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.316435813903809,
      "learning_rate": 2.97e-05,
      "loss": 3.3521,
      "step": 8120
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.267094612121582,
      "learning_rate": 2.9675000000000003e-05,
      "loss": 3.2617,
      "step": 8130
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.106855392456055,
      "learning_rate": 2.965e-05,
      "loss": 3.2412,
      "step": 8140
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.416605949401855,
      "learning_rate": 2.9625000000000002e-05,
      "loss": 3.1098,
      "step": 8150
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.247210502624512,
      "learning_rate": 2.96e-05,
      "loss": 3.677,
      "step": 8160
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.980013370513916,
      "learning_rate": 2.9575000000000004e-05,
      "loss": 3.31,
      "step": 8170
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.369775772094727,
      "learning_rate": 2.955e-05,
      "loss": 3.0275,
      "step": 8180
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.34135913848877,
      "learning_rate": 2.9525000000000003e-05,
      "loss": 3.1576,
      "step": 8190
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.094682693481445,
      "learning_rate": 2.95e-05,
      "loss": 3.2979,
      "step": 8200
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.459935188293457,
      "learning_rate": 2.9475e-05,
      "loss": 3.2461,
      "step": 8210
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.717995643615723,
      "learning_rate": 2.945e-05,
      "loss": 3.1547,
      "step": 8220
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.828369140625,
      "learning_rate": 2.9425000000000004e-05,
      "loss": 3.1826,
      "step": 8230
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.361169815063477,
      "learning_rate": 2.94e-05,
      "loss": 3.0059,
      "step": 8240
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.55051326751709,
      "learning_rate": 2.9375000000000003e-05,
      "loss": 3.1461,
      "step": 8250
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.318455696105957,
      "learning_rate": 2.935e-05,
      "loss": 3.5658,
      "step": 8260
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.037154197692871,
      "learning_rate": 2.9325e-05,
      "loss": 3.3076,
      "step": 8270
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.11845874786377,
      "learning_rate": 2.93e-05,
      "loss": 3.1104,
      "step": 8280
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.402087211608887,
      "learning_rate": 2.9275000000000003e-05,
      "loss": 3.2119,
      "step": 8290
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.8711519241333,
      "learning_rate": 2.925e-05,
      "loss": 3.4324,
      "step": 8300
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.933578491210938,
      "learning_rate": 2.9225000000000002e-05,
      "loss": 3.3176,
      "step": 8310
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.754261016845703,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 3.107,
      "step": 8320
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.395316123962402,
      "learning_rate": 2.9175e-05,
      "loss": 3.098,
      "step": 8330
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.648923873901367,
      "learning_rate": 2.915e-05,
      "loss": 3.1779,
      "step": 8340
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.946639060974121,
      "learning_rate": 2.9125000000000003e-05,
      "loss": 3.3973,
      "step": 8350
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.121849060058594,
      "learning_rate": 2.91e-05,
      "loss": 3.4475,
      "step": 8360
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.067516326904297,
      "learning_rate": 2.9075000000000002e-05,
      "loss": 3.0273,
      "step": 8370
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.938167572021484,
      "learning_rate": 2.9049999999999998e-05,
      "loss": 3.1738,
      "step": 8380
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.657791137695312,
      "learning_rate": 2.9025e-05,
      "loss": 3.3842,
      "step": 8390
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.188743591308594,
      "learning_rate": 2.9e-05,
      "loss": 3.3094,
      "step": 8400
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.116207122802734,
      "learning_rate": 2.8975000000000003e-05,
      "loss": 3.2527,
      "step": 8410
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.016372680664062,
      "learning_rate": 2.895e-05,
      "loss": 3.2104,
      "step": 8420
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.12134838104248,
      "learning_rate": 2.8925000000000002e-05,
      "loss": 3.0822,
      "step": 8430
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.555516242980957,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 2.9709,
      "step": 8440
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.473855018615723,
      "learning_rate": 2.8875e-05,
      "loss": 3.4768,
      "step": 8450
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.417205810546875,
      "learning_rate": 2.885e-05,
      "loss": 3.5086,
      "step": 8460
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.128740310668945,
      "learning_rate": 2.8825000000000003e-05,
      "loss": 3.3559,
      "step": 8470
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.025940895080566,
      "learning_rate": 2.88e-05,
      "loss": 3.4473,
      "step": 8480
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.539159774780273,
      "learning_rate": 2.8775e-05,
      "loss": 3.0928,
      "step": 8490
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.18291187286377,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 2.9484,
      "step": 8500
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.03377718986002722,
      "eval_rouge-1": 32.300636,
      "eval_rouge-2": 7.070941999999999,
      "eval_rouge-l": 25.22933,
      "eval_runtime": 55.9465,
      "eval_samples_per_second": 0.894,
      "eval_steps_per_second": 0.071,
      "step": 8500
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.435405731201172,
      "learning_rate": 2.8725e-05,
      "loss": 3.3734,
      "step": 8510
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.60223388671875,
      "learning_rate": 2.87e-05,
      "loss": 3.0088,
      "step": 8520
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.539097785949707,
      "learning_rate": 2.8675000000000002e-05,
      "loss": 3.4188,
      "step": 8530
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.30924129486084,
      "learning_rate": 2.865e-05,
      "loss": 3.024,
      "step": 8540
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.481486320495605,
      "learning_rate": 2.8625e-05,
      "loss": 3.3971,
      "step": 8550
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.287694931030273,
      "learning_rate": 2.86e-05,
      "loss": 3.0682,
      "step": 8560
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.320164680480957,
      "learning_rate": 2.8575000000000003e-05,
      "loss": 3.242,
      "step": 8570
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.947702407836914,
      "learning_rate": 2.855e-05,
      "loss": 3.1471,
      "step": 8580
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.989943504333496,
      "learning_rate": 2.8525000000000002e-05,
      "loss": 3.1979,
      "step": 8590
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.576605796813965,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.4217,
      "step": 8600
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.77236270904541,
      "learning_rate": 2.8475e-05,
      "loss": 3.4398,
      "step": 8610
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.605798721313477,
      "learning_rate": 2.845e-05,
      "loss": 3.3924,
      "step": 8620
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.400259971618652,
      "learning_rate": 2.8425000000000003e-05,
      "loss": 3.157,
      "step": 8630
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.073420524597168,
      "learning_rate": 2.84e-05,
      "loss": 3.3697,
      "step": 8640
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.604317665100098,
      "learning_rate": 2.8375000000000002e-05,
      "loss": 2.8838,
      "step": 8650
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.915363311767578,
      "learning_rate": 2.8349999999999998e-05,
      "loss": 3.3805,
      "step": 8660
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.27149486541748,
      "learning_rate": 2.8325e-05,
      "loss": 3.3684,
      "step": 8670
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.971842765808105,
      "learning_rate": 2.83e-05,
      "loss": 3.1633,
      "step": 8680
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.04385757446289,
      "learning_rate": 2.8275000000000003e-05,
      "loss": 3.0967,
      "step": 8690
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.840357780456543,
      "learning_rate": 2.825e-05,
      "loss": 3.4898,
      "step": 8700
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.061192512512207,
      "learning_rate": 2.8225e-05,
      "loss": 3.3793,
      "step": 8710
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.036474227905273,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 3.0555,
      "step": 8720
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.603776454925537,
      "learning_rate": 2.8175e-05,
      "loss": 3.2381,
      "step": 8730
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.143543243408203,
      "learning_rate": 2.815e-05,
      "loss": 3.2227,
      "step": 8740
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.278641700744629,
      "learning_rate": 2.8125000000000003e-05,
      "loss": 3.2629,
      "step": 8750
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.490640640258789,
      "learning_rate": 2.8100000000000005e-05,
      "loss": 2.9768,
      "step": 8760
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.883599281311035,
      "learning_rate": 2.8075e-05,
      "loss": 3.4531,
      "step": 8770
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.470476150512695,
      "learning_rate": 2.8050000000000004e-05,
      "loss": 3.3107,
      "step": 8780
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.593155860900879,
      "learning_rate": 2.8025e-05,
      "loss": 3.2115,
      "step": 8790
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.282546997070312,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.1742,
      "step": 8800
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.492552757263184,
      "learning_rate": 2.7975000000000002e-05,
      "loss": 3.1219,
      "step": 8810
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.970721244812012,
      "learning_rate": 2.7950000000000005e-05,
      "loss": 3.3334,
      "step": 8820
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.965391159057617,
      "learning_rate": 2.7925e-05,
      "loss": 3.5873,
      "step": 8830
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.628028869628906,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 3.1334,
      "step": 8840
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.362961769104004,
      "learning_rate": 2.7875e-05,
      "loss": 3.2068,
      "step": 8850
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.970517158508301,
      "learning_rate": 2.7850000000000003e-05,
      "loss": 3.5414,
      "step": 8860
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.129687309265137,
      "learning_rate": 2.7825000000000002e-05,
      "loss": 3.3273,
      "step": 8870
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.046342849731445,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 2.9762,
      "step": 8880
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.902196884155273,
      "learning_rate": 2.7775e-05,
      "loss": 3.3289,
      "step": 8890
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.722981452941895,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 3.3291,
      "step": 8900
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.374682426452637,
      "learning_rate": 2.7725e-05,
      "loss": 3.1262,
      "step": 8910
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.294238090515137,
      "learning_rate": 2.7700000000000002e-05,
      "loss": 3.2236,
      "step": 8920
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.260683059692383,
      "learning_rate": 2.7675000000000002e-05,
      "loss": 3.2223,
      "step": 8930
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.957840919494629,
      "learning_rate": 2.7650000000000005e-05,
      "loss": 3.308,
      "step": 8940
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.972100257873535,
      "learning_rate": 2.7625e-05,
      "loss": 2.9816,
      "step": 8950
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.512129783630371,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 3.4133,
      "step": 8960
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.61739730834961,
      "learning_rate": 2.7575e-05,
      "loss": 3.1307,
      "step": 8970
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.494691848754883,
      "learning_rate": 2.7550000000000002e-05,
      "loss": 3.1892,
      "step": 8980
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.174629211425781,
      "learning_rate": 2.7525e-05,
      "loss": 2.9625,
      "step": 8990
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.774114608764648,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.0764,
      "step": 9000
    },
    {
      "epoch": 0.08,
      "eval_bleu-4": 0.03650927391308568,
      "eval_rouge-1": 33.390696000000005,
      "eval_rouge-2": 7.801134000000001,
      "eval_rouge-l": 24.950526,
      "eval_runtime": 53.972,
      "eval_samples_per_second": 0.926,
      "eval_steps_per_second": 0.074,
      "step": 9000
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.742344856262207,
      "learning_rate": 2.7475e-05,
      "loss": 3.5959,
      "step": 9010
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.129371643066406,
      "learning_rate": 2.7450000000000003e-05,
      "loss": 3.3514,
      "step": 9020
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.253981590270996,
      "learning_rate": 2.7425e-05,
      "loss": 2.8014,
      "step": 9030
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.590543746948242,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 3.0654,
      "step": 9040
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.992104530334473,
      "learning_rate": 2.7375e-05,
      "loss": 3.1898,
      "step": 9050
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.822613716125488,
      "learning_rate": 2.7350000000000004e-05,
      "loss": 3.4008,
      "step": 9060
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.435373306274414,
      "learning_rate": 2.7325e-05,
      "loss": 3.0547,
      "step": 9070
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.066635608673096,
      "learning_rate": 2.7300000000000003e-05,
      "loss": 3.4629,
      "step": 9080
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.805999755859375,
      "learning_rate": 2.7275e-05,
      "loss": 3.1066,
      "step": 9090
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.157567977905273,
      "learning_rate": 2.725e-05,
      "loss": 3.3951,
      "step": 9100
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.846987247467041,
      "learning_rate": 2.7225e-05,
      "loss": 3.3467,
      "step": 9110
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.992673873901367,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 3.3855,
      "step": 9120
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.7423677444458,
      "learning_rate": 2.7175e-05,
      "loss": 3.033,
      "step": 9130
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.517605781555176,
      "learning_rate": 2.7150000000000003e-05,
      "loss": 3.0182,
      "step": 9140
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.785929679870605,
      "learning_rate": 2.7125000000000002e-05,
      "loss": 3.2223,
      "step": 9150
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.159195899963379,
      "learning_rate": 2.7100000000000005e-05,
      "loss": 3.184,
      "step": 9160
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.035269737243652,
      "learning_rate": 2.7075e-05,
      "loss": 3.1418,
      "step": 9170
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.15467643737793,
      "learning_rate": 2.7050000000000004e-05,
      "loss": 3.2422,
      "step": 9180
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.993218421936035,
      "learning_rate": 2.7025e-05,
      "loss": 3.2768,
      "step": 9190
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.134068489074707,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.1033,
      "step": 9200
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.984199523925781,
      "learning_rate": 2.6975000000000002e-05,
      "loss": 3.0748,
      "step": 9210
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.594880104064941,
      "learning_rate": 2.6950000000000005e-05,
      "loss": 3.2031,
      "step": 9220
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.589184761047363,
      "learning_rate": 2.6925e-05,
      "loss": 3.1211,
      "step": 9230
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.951831817626953,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 3.2084,
      "step": 9240
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.035463333129883,
      "learning_rate": 2.6875e-05,
      "loss": 3.14,
      "step": 9250
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.809778213500977,
      "learning_rate": 2.6850000000000002e-05,
      "loss": 3.4395,
      "step": 9260
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.467443466186523,
      "learning_rate": 2.6825e-05,
      "loss": 2.9937,
      "step": 9270
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.753880500793457,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 3.2023,
      "step": 9280
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.214966773986816,
      "learning_rate": 2.6775e-05,
      "loss": 3.1334,
      "step": 9290
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.996335983276367,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 3.3283,
      "step": 9300
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.026809692382812,
      "learning_rate": 2.6725e-05,
      "loss": 3.0799,
      "step": 9310
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.976506233215332,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 3.1965,
      "step": 9320
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.92784595489502,
      "learning_rate": 2.6675e-05,
      "loss": 3.4934,
      "step": 9330
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.265924453735352,
      "learning_rate": 2.6650000000000004e-05,
      "loss": 3.249,
      "step": 9340
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.69663143157959,
      "learning_rate": 2.6625e-05,
      "loss": 3.118,
      "step": 9350
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.020501136779785,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 3.0264,
      "step": 9360
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.694769859313965,
      "learning_rate": 2.6575e-05,
      "loss": 2.7412,
      "step": 9370
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.14210319519043,
      "learning_rate": 2.655e-05,
      "loss": 3.1758,
      "step": 9380
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.99979019165039,
      "learning_rate": 2.6525e-05,
      "loss": 3.2225,
      "step": 9390
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.694594383239746,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.2715,
      "step": 9400
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.23115348815918,
      "learning_rate": 2.6475e-05,
      "loss": 3.0475,
      "step": 9410
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.478979110717773,
      "learning_rate": 2.6450000000000003e-05,
      "loss": 3.1893,
      "step": 9420
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.101529121398926,
      "learning_rate": 2.6425e-05,
      "loss": 3.4277,
      "step": 9430
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.173304557800293,
      "learning_rate": 2.64e-05,
      "loss": 3.2818,
      "step": 9440
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.460853576660156,
      "learning_rate": 2.6375e-05,
      "loss": 3.4463,
      "step": 9450
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.234847068786621,
      "learning_rate": 2.6350000000000004e-05,
      "loss": 3.1359,
      "step": 9460
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.985480308532715,
      "learning_rate": 2.6325e-05,
      "loss": 2.9133,
      "step": 9470
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.386907577514648,
      "learning_rate": 2.6300000000000002e-05,
      "loss": 3.1344,
      "step": 9480
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.754472732543945,
      "learning_rate": 2.6275e-05,
      "loss": 3.5428,
      "step": 9490
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.363103866577148,
      "learning_rate": 2.625e-05,
      "loss": 3.1094,
      "step": 9500
    },
    {
      "epoch": 0.08,
      "eval_bleu-4": 0.03305945423381071,
      "eval_rouge-1": 32.729569999999995,
      "eval_rouge-2": 6.913125999999998,
      "eval_rouge-l": 25.529588,
      "eval_runtime": 43.344,
      "eval_samples_per_second": 1.154,
      "eval_steps_per_second": 0.092,
      "step": 9500
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.050539016723633,
      "learning_rate": 2.6225e-05,
      "loss": 3.3406,
      "step": 9510
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.508390426635742,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 3.4037,
      "step": 9520
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.004313468933105,
      "learning_rate": 2.6175e-05,
      "loss": 2.9229,
      "step": 9530
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.1609468460083,
      "learning_rate": 2.6150000000000002e-05,
      "loss": 3.2777,
      "step": 9540
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.778657913208008,
      "learning_rate": 2.6124999999999998e-05,
      "loss": 3.1689,
      "step": 9550
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.451464653015137,
      "learning_rate": 2.61e-05,
      "loss": 2.9617,
      "step": 9560
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.408161163330078,
      "learning_rate": 2.6075e-05,
      "loss": 3.2633,
      "step": 9570
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.417993545532227,
      "learning_rate": 2.6050000000000003e-05,
      "loss": 3.3793,
      "step": 9580
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.978363037109375,
      "learning_rate": 2.6025e-05,
      "loss": 3.3455,
      "step": 9590
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.307007312774658,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.1648,
      "step": 9600
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.4251127243042,
      "learning_rate": 2.5974999999999998e-05,
      "loss": 3.4797,
      "step": 9610
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.364331245422363,
      "learning_rate": 2.595e-05,
      "loss": 3.2547,
      "step": 9620
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.518160820007324,
      "learning_rate": 2.5925e-05,
      "loss": 3.2066,
      "step": 9630
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.902029991149902,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 3.2764,
      "step": 9640
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.057092666625977,
      "learning_rate": 2.5875e-05,
      "loss": 3.1434,
      "step": 9650
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.895834922790527,
      "learning_rate": 2.585e-05,
      "loss": 3.0516,
      "step": 9660
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.02609920501709,
      "learning_rate": 2.5824999999999998e-05,
      "loss": 3.2783,
      "step": 9670
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.42337417602539,
      "learning_rate": 2.58e-05,
      "loss": 3.0678,
      "step": 9680
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.162227630615234,
      "learning_rate": 2.5775e-05,
      "loss": 3.2812,
      "step": 9690
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.40233039855957,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 3.5791,
      "step": 9700
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.24382495880127,
      "learning_rate": 2.5725e-05,
      "loss": 3.1732,
      "step": 9710
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.934172630310059,
      "learning_rate": 2.57e-05,
      "loss": 2.8621,
      "step": 9720
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.7561116218566895,
      "learning_rate": 2.5675e-05,
      "loss": 3.1002,
      "step": 9730
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.714794158935547,
      "learning_rate": 2.5650000000000003e-05,
      "loss": 3.0572,
      "step": 9740
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.416111946105957,
      "learning_rate": 2.5625e-05,
      "loss": 3.3189,
      "step": 9750
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.875646591186523,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 3.4262,
      "step": 9760
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.652885437011719,
      "learning_rate": 2.5574999999999998e-05,
      "loss": 3.0668,
      "step": 9770
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.107436180114746,
      "learning_rate": 2.555e-05,
      "loss": 3.0623,
      "step": 9780
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.62049388885498,
      "learning_rate": 2.5525e-05,
      "loss": 3.0486,
      "step": 9790
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.814579963684082,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.3588,
      "step": 9800
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.392292976379395,
      "learning_rate": 2.5475e-05,
      "loss": 3.29,
      "step": 9810
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.53431510925293,
      "learning_rate": 2.5450000000000002e-05,
      "loss": 3.2012,
      "step": 9820
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.922002792358398,
      "learning_rate": 2.5424999999999998e-05,
      "loss": 3.0875,
      "step": 9830
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.226362228393555,
      "learning_rate": 2.54e-05,
      "loss": 3.0174,
      "step": 9840
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.470537185668945,
      "learning_rate": 2.5375e-05,
      "loss": 3.1486,
      "step": 9850
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.004966735839844,
      "learning_rate": 2.5350000000000003e-05,
      "loss": 3.3256,
      "step": 9860
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.836027145385742,
      "learning_rate": 2.5325e-05,
      "loss": 2.9715,
      "step": 9870
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.215263366699219,
      "learning_rate": 2.5300000000000002e-05,
      "loss": 2.9445,
      "step": 9880
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.738306999206543,
      "learning_rate": 2.5274999999999998e-05,
      "loss": 3.2547,
      "step": 9890
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.058053970336914,
      "learning_rate": 2.525e-05,
      "loss": 3.3807,
      "step": 9900
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.862451553344727,
      "learning_rate": 2.5225e-05,
      "loss": 3.3781,
      "step": 9910
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.364765167236328,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 3.067,
      "step": 9920
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.244762420654297,
      "learning_rate": 2.5175e-05,
      "loss": 3.0305,
      "step": 9930
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.128251075744629,
      "learning_rate": 2.515e-05,
      "loss": 3.0914,
      "step": 9940
    },
    {
      "epoch": 0.09,
      "grad_norm": 13.897128105163574,
      "learning_rate": 2.5124999999999997e-05,
      "loss": 3.6389,
      "step": 9950
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.712779998779297,
      "learning_rate": 2.51e-05,
      "loss": 3.4705,
      "step": 9960
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.137238502502441,
      "learning_rate": 2.5075e-05,
      "loss": 3.1869,
      "step": 9970
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.232925415039062,
      "learning_rate": 2.5050000000000002e-05,
      "loss": 3.1762,
      "step": 9980
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.757966995239258,
      "learning_rate": 2.5025e-05,
      "loss": 3.2385,
      "step": 9990
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.094572067260742,
      "learning_rate": 2.5e-05,
      "loss": 3.2398,
      "step": 10000
    },
    {
      "epoch": 0.09,
      "eval_bleu-4": 0.03437029132047479,
      "eval_rouge-1": 30.909728,
      "eval_rouge-2": 6.938262,
      "eval_rouge-l": 24.322090000000003,
      "eval_runtime": 72.738,
      "eval_samples_per_second": 0.687,
      "eval_steps_per_second": 0.055,
      "step": 10000
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.263206481933594,
      "learning_rate": 2.4975e-05,
      "loss": 3.0617,
      "step": 10010
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.055377006530762,
      "learning_rate": 2.495e-05,
      "loss": 3.2232,
      "step": 10020
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.444465637207031,
      "learning_rate": 2.4925000000000003e-05,
      "loss": 3.0543,
      "step": 10030
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.735764503479004,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 3.2834,
      "step": 10040
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.453150749206543,
      "learning_rate": 2.4875e-05,
      "loss": 3.2365,
      "step": 10050
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.804058074951172,
      "learning_rate": 2.485e-05,
      "loss": 3.1934,
      "step": 10060
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.922952651977539,
      "learning_rate": 2.4825e-05,
      "loss": 3.0996,
      "step": 10070
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.755791664123535,
      "learning_rate": 2.48e-05,
      "loss": 3.1637,
      "step": 10080
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.118792533874512,
      "learning_rate": 2.4775000000000003e-05,
      "loss": 3.1504,
      "step": 10090
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.95737361907959,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 2.8097,
      "step": 10100
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.319803237915039,
      "learning_rate": 2.4725e-05,
      "loss": 3.209,
      "step": 10110
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.298544883728027,
      "learning_rate": 2.47e-05,
      "loss": 3.2125,
      "step": 10120
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.042320251464844,
      "learning_rate": 2.4675e-05,
      "loss": 3.2465,
      "step": 10130
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.14651870727539,
      "learning_rate": 2.465e-05,
      "loss": 3.4156,
      "step": 10140
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.715084075927734,
      "learning_rate": 2.4625000000000002e-05,
      "loss": 3.0852,
      "step": 10150
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.705744743347168,
      "learning_rate": 2.46e-05,
      "loss": 3.2236,
      "step": 10160
    },
    {
      "epoch": 0.09,
      "grad_norm": 13.4420747756958,
      "learning_rate": 2.4575e-05,
      "loss": 3.1959,
      "step": 10170
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.333179473876953,
      "learning_rate": 2.455e-05,
      "loss": 3.2516,
      "step": 10180
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.421354293823242,
      "learning_rate": 2.4525e-05,
      "loss": 3.0887,
      "step": 10190
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.105392456054688,
      "learning_rate": 2.45e-05,
      "loss": 3.3229,
      "step": 10200
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.09445858001709,
      "learning_rate": 2.4475000000000002e-05,
      "loss": 3.1326,
      "step": 10210
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.303389072418213,
      "learning_rate": 2.445e-05,
      "loss": 3.1777,
      "step": 10220
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.68951940536499,
      "learning_rate": 2.4425e-05,
      "loss": 3.3119,
      "step": 10230
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.561270713806152,
      "learning_rate": 2.44e-05,
      "loss": 3.2523,
      "step": 10240
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.60159969329834,
      "learning_rate": 2.4375e-05,
      "loss": 3.2752,
      "step": 10250
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.35582447052002,
      "learning_rate": 2.435e-05,
      "loss": 3.1756,
      "step": 10260
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.194615364074707,
      "learning_rate": 2.4325000000000002e-05,
      "loss": 3.3539,
      "step": 10270
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.448698043823242,
      "learning_rate": 2.43e-05,
      "loss": 3.3617,
      "step": 10280
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.835470199584961,
      "learning_rate": 2.4275e-05,
      "loss": 3.4398,
      "step": 10290
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.815620422363281,
      "learning_rate": 2.425e-05,
      "loss": 3.2465,
      "step": 10300
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.50702953338623,
      "learning_rate": 2.4225e-05,
      "loss": 3.3799,
      "step": 10310
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.424453735351562,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 3.1334,
      "step": 10320
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.173988342285156,
      "learning_rate": 2.4175e-05,
      "loss": 3.1688,
      "step": 10330
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.840819835662842,
      "learning_rate": 2.415e-05,
      "loss": 3.2576,
      "step": 10340
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.789366722106934,
      "learning_rate": 2.4125e-05,
      "loss": 3.2021,
      "step": 10350
    },
    {
      "epoch": 0.09,
      "grad_norm": 14.676994323730469,
      "learning_rate": 2.41e-05,
      "loss": 3.2705,
      "step": 10360
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.755755424499512,
      "learning_rate": 2.4075e-05,
      "loss": 3.3359,
      "step": 10370
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.940993309020996,
      "learning_rate": 2.4050000000000002e-05,
      "loss": 3.2967,
      "step": 10380
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.470534324645996,
      "learning_rate": 2.4025e-05,
      "loss": 3.274,
      "step": 10390
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.292946815490723,
      "learning_rate": 2.4e-05,
      "loss": 3.3494,
      "step": 10400
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.533010005950928,
      "learning_rate": 2.3975e-05,
      "loss": 3.3748,
      "step": 10410
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.56489086151123,
      "learning_rate": 2.395e-05,
      "loss": 2.9418,
      "step": 10420
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.63453483581543,
      "learning_rate": 2.3925e-05,
      "loss": 3.4303,
      "step": 10430
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.511131286621094,
      "learning_rate": 2.39e-05,
      "loss": 3.0748,
      "step": 10440
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.684651374816895,
      "learning_rate": 2.3875e-05,
      "loss": 3.1654,
      "step": 10450
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.663313865661621,
      "learning_rate": 2.385e-05,
      "loss": 3.2723,
      "step": 10460
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.90202522277832,
      "learning_rate": 2.3825e-05,
      "loss": 3.5207,
      "step": 10470
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.879743576049805,
      "learning_rate": 2.38e-05,
      "loss": 3.051,
      "step": 10480
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.590331077575684,
      "learning_rate": 2.3775e-05,
      "loss": 3.3234,
      "step": 10490
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.20289134979248,
      "learning_rate": 2.375e-05,
      "loss": 3.3986,
      "step": 10500
    },
    {
      "epoch": 0.09,
      "eval_bleu-4": 0.03564721749022186,
      "eval_rouge-1": 32.440924,
      "eval_rouge-2": 6.664822,
      "eval_rouge-l": 25.210974,
      "eval_runtime": 41.5532,
      "eval_samples_per_second": 1.203,
      "eval_steps_per_second": 0.096,
      "step": 10500
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.848516464233398,
      "learning_rate": 2.3725e-05,
      "loss": 3.315,
      "step": 10510
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.862384796142578,
      "learning_rate": 2.37e-05,
      "loss": 3.2736,
      "step": 10520
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.909808158874512,
      "learning_rate": 2.3675e-05,
      "loss": 3.3105,
      "step": 10530
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.714167594909668,
      "learning_rate": 2.365e-05,
      "loss": 3.2277,
      "step": 10540
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.432563781738281,
      "learning_rate": 2.3624999999999998e-05,
      "loss": 3.4016,
      "step": 10550
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.160432815551758,
      "learning_rate": 2.36e-05,
      "loss": 3.0875,
      "step": 10560
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.608638763427734,
      "learning_rate": 2.3575e-05,
      "loss": 3.3369,
      "step": 10570
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.429201126098633,
      "learning_rate": 2.355e-05,
      "loss": 3.3051,
      "step": 10580
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.515556335449219,
      "learning_rate": 2.3525e-05,
      "loss": 3.3426,
      "step": 10590
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.161362648010254,
      "learning_rate": 2.35e-05,
      "loss": 2.9117,
      "step": 10600
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.475659370422363,
      "learning_rate": 2.3475e-05,
      "loss": 3.3148,
      "step": 10610
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.920254707336426,
      "learning_rate": 2.345e-05,
      "loss": 3.1625,
      "step": 10620
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.057046890258789,
      "learning_rate": 2.3425000000000004e-05,
      "loss": 3.2645,
      "step": 10630
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.805403709411621,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 2.9441,
      "step": 10640
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.088844299316406,
      "learning_rate": 2.3375000000000002e-05,
      "loss": 3.1771,
      "step": 10650
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.44640827178955,
      "learning_rate": 2.3350000000000002e-05,
      "loss": 3.3895,
      "step": 10660
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.688519477844238,
      "learning_rate": 2.3325e-05,
      "loss": 3.2166,
      "step": 10670
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.028749465942383,
      "learning_rate": 2.3300000000000004e-05,
      "loss": 3.1582,
      "step": 10680
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.563591957092285,
      "learning_rate": 2.3275000000000003e-05,
      "loss": 2.9795,
      "step": 10690
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.13088846206665,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 3.0305,
      "step": 10700
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.103189468383789,
      "learning_rate": 2.3225000000000002e-05,
      "loss": 3.234,
      "step": 10710
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.471338272094727,
      "learning_rate": 2.32e-05,
      "loss": 3.1816,
      "step": 10720
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.00522518157959,
      "learning_rate": 2.3175e-05,
      "loss": 3.3889,
      "step": 10730
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.075352668762207,
      "learning_rate": 2.3150000000000004e-05,
      "loss": 3.4451,
      "step": 10740
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.329736709594727,
      "learning_rate": 2.3125000000000003e-05,
      "loss": 3.2733,
      "step": 10750
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.464598655700684,
      "learning_rate": 2.3100000000000002e-05,
      "loss": 3.1025,
      "step": 10760
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.525455474853516,
      "learning_rate": 2.3075000000000002e-05,
      "loss": 3.0274,
      "step": 10770
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.631648063659668,
      "learning_rate": 2.305e-05,
      "loss": 3.2078,
      "step": 10780
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.91444206237793,
      "learning_rate": 2.3025e-05,
      "loss": 3.5129,
      "step": 10790
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.835402488708496,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.3049,
      "step": 10800
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.188277244567871,
      "learning_rate": 2.2975000000000003e-05,
      "loss": 3.3609,
      "step": 10810
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.664258003234863,
      "learning_rate": 2.2950000000000002e-05,
      "loss": 3.2361,
      "step": 10820
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.47207260131836,
      "learning_rate": 2.2925e-05,
      "loss": 3.1539,
      "step": 10830
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.467248916625977,
      "learning_rate": 2.29e-05,
      "loss": 3.2645,
      "step": 10840
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.392160415649414,
      "learning_rate": 2.2875e-05,
      "loss": 3.0954,
      "step": 10850
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.86156940460205,
      "learning_rate": 2.2850000000000003e-05,
      "loss": 3.1877,
      "step": 10860
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.8557209968566895,
      "learning_rate": 2.2825000000000003e-05,
      "loss": 2.9971,
      "step": 10870
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.449830055236816,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 3.0773,
      "step": 10880
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.978891372680664,
      "learning_rate": 2.2775e-05,
      "loss": 3.2588,
      "step": 10890
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.066761016845703,
      "learning_rate": 2.275e-05,
      "loss": 3.2129,
      "step": 10900
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.331513404846191,
      "learning_rate": 2.2725000000000003e-05,
      "loss": 3.2768,
      "step": 10910
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.180316925048828,
      "learning_rate": 2.2700000000000003e-05,
      "loss": 3.2035,
      "step": 10920
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.040143966674805,
      "learning_rate": 2.2675000000000002e-05,
      "loss": 3.3293,
      "step": 10930
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.707988739013672,
      "learning_rate": 2.265e-05,
      "loss": 2.8578,
      "step": 10940
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.298039436340332,
      "learning_rate": 2.2625e-05,
      "loss": 3.2141,
      "step": 10950
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.941055297851562,
      "learning_rate": 2.26e-05,
      "loss": 3.483,
      "step": 10960
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.950970649719238,
      "learning_rate": 2.2575000000000003e-05,
      "loss": 3.3869,
      "step": 10970
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.364296913146973,
      "learning_rate": 2.2550000000000003e-05,
      "loss": 3.4611,
      "step": 10980
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.903961181640625,
      "learning_rate": 2.2525000000000002e-05,
      "loss": 3.3266,
      "step": 10990
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.033712387084961,
      "learning_rate": 2.25e-05,
      "loss": 3.1158,
      "step": 11000
    },
    {
      "epoch": 0.1,
      "eval_bleu-4": 0.0356134937750179,
      "eval_rouge-1": 32.809384,
      "eval_rouge-2": 6.916984,
      "eval_rouge-l": 25.132572,
      "eval_runtime": 26.96,
      "eval_samples_per_second": 1.855,
      "eval_steps_per_second": 0.148,
      "step": 11000
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.490018844604492,
      "learning_rate": 2.2475e-05,
      "loss": 3.0922,
      "step": 11010
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.345696449279785,
      "learning_rate": 2.245e-05,
      "loss": 3.1578,
      "step": 11020
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.472000122070312,
      "learning_rate": 2.2425000000000003e-05,
      "loss": 3.3258,
      "step": 11030
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.6353120803833,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 3.2807,
      "step": 11040
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.289355278015137,
      "learning_rate": 2.2375000000000002e-05,
      "loss": 3.2602,
      "step": 11050
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.63325309753418,
      "learning_rate": 2.235e-05,
      "loss": 3.0075,
      "step": 11060
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.506048202514648,
      "learning_rate": 2.2325e-05,
      "loss": 3.1654,
      "step": 11070
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.284833908081055,
      "learning_rate": 2.23e-05,
      "loss": 3.2693,
      "step": 11080
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.911076545715332,
      "learning_rate": 2.2275000000000003e-05,
      "loss": 2.9041,
      "step": 11090
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.349770545959473,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 3.1361,
      "step": 11100
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.92885684967041,
      "learning_rate": 2.2225e-05,
      "loss": 3.2256,
      "step": 11110
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.034399032592773,
      "learning_rate": 2.22e-05,
      "loss": 3.0877,
      "step": 11120
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.965435981750488,
      "learning_rate": 2.2175e-05,
      "loss": 3.151,
      "step": 11130
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.942564964294434,
      "learning_rate": 2.215e-05,
      "loss": 3.1043,
      "step": 11140
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.668176651000977,
      "learning_rate": 2.2125000000000002e-05,
      "loss": 3.234,
      "step": 11150
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.974581718444824,
      "learning_rate": 2.2100000000000002e-05,
      "loss": 2.9936,
      "step": 11160
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.38955307006836,
      "learning_rate": 2.2075e-05,
      "loss": 3.0832,
      "step": 11170
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.353697776794434,
      "learning_rate": 2.205e-05,
      "loss": 3.0688,
      "step": 11180
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.910247325897217,
      "learning_rate": 2.2025e-05,
      "loss": 3.0398,
      "step": 11190
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.54296875,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.0812,
      "step": 11200
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.741515159606934,
      "learning_rate": 2.1975000000000002e-05,
      "loss": 3.316,
      "step": 11210
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.40433120727539,
      "learning_rate": 2.195e-05,
      "loss": 3.1031,
      "step": 11220
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.326438903808594,
      "learning_rate": 2.1925e-05,
      "loss": 3.5793,
      "step": 11230
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.654959678649902,
      "learning_rate": 2.19e-05,
      "loss": 3.0346,
      "step": 11240
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.633031845092773,
      "learning_rate": 2.1875e-05,
      "loss": 3.0838,
      "step": 11250
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.778190612792969,
      "learning_rate": 2.1850000000000003e-05,
      "loss": 3.4217,
      "step": 11260
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.569637298583984,
      "learning_rate": 2.1825000000000002e-05,
      "loss": 3.0467,
      "step": 11270
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.582642555236816,
      "learning_rate": 2.18e-05,
      "loss": 3.3486,
      "step": 11280
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.877754211425781,
      "learning_rate": 2.1775e-05,
      "loss": 2.8976,
      "step": 11290
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.024117469787598,
      "learning_rate": 2.175e-05,
      "loss": 3.3553,
      "step": 11300
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.761813163757324,
      "learning_rate": 2.1725e-05,
      "loss": 3.2254,
      "step": 11310
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.712807655334473,
      "learning_rate": 2.1700000000000002e-05,
      "loss": 3.3523,
      "step": 11320
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.218421936035156,
      "learning_rate": 2.1675e-05,
      "loss": 3.0027,
      "step": 11330
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.906292915344238,
      "learning_rate": 2.165e-05,
      "loss": 3.308,
      "step": 11340
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.599310874938965,
      "learning_rate": 2.1625e-05,
      "loss": 3.3117,
      "step": 11350
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.722516059875488,
      "learning_rate": 2.16e-05,
      "loss": 3.3539,
      "step": 11360
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.897788047790527,
      "learning_rate": 2.1575e-05,
      "loss": 3.3303,
      "step": 11370
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.076509475708008,
      "learning_rate": 2.1550000000000002e-05,
      "loss": 3.0658,
      "step": 11380
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.27182674407959,
      "learning_rate": 2.1525e-05,
      "loss": 3.3512,
      "step": 11390
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.12389087677002,
      "learning_rate": 2.15e-05,
      "loss": 3.2814,
      "step": 11400
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.31505012512207,
      "learning_rate": 2.1475e-05,
      "loss": 3.1383,
      "step": 11410
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.985472679138184,
      "learning_rate": 2.145e-05,
      "loss": 3.2422,
      "step": 11420
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.748270988464355,
      "learning_rate": 2.1425e-05,
      "loss": 3.248,
      "step": 11430
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.405604362487793,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 3.1926,
      "step": 11440
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.942841529846191,
      "learning_rate": 2.1375e-05,
      "loss": 3.524,
      "step": 11450
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.190176963806152,
      "learning_rate": 2.135e-05,
      "loss": 3.1115,
      "step": 11460
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.490715026855469,
      "learning_rate": 2.1325e-05,
      "loss": 3.259,
      "step": 11470
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.90634822845459,
      "learning_rate": 2.13e-05,
      "loss": 2.874,
      "step": 11480
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.905808448791504,
      "learning_rate": 2.1275000000000002e-05,
      "loss": 3.2932,
      "step": 11490
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.585099220275879,
      "learning_rate": 2.125e-05,
      "loss": 3.4551,
      "step": 11500
    },
    {
      "epoch": 0.1,
      "eval_bleu-4": 0.03873422449673732,
      "eval_rouge-1": 32.596428,
      "eval_rouge-2": 7.501508,
      "eval_rouge-l": 25.922489999999996,
      "eval_runtime": 45.1787,
      "eval_samples_per_second": 1.107,
      "eval_steps_per_second": 0.089,
      "step": 11500
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.09211540222168,
      "learning_rate": 2.1225e-05,
      "loss": 3.2625,
      "step": 11510
    },
    {
      "epoch": 0.1,
      "grad_norm": 13.084569931030273,
      "learning_rate": 2.12e-05,
      "loss": 3.2633,
      "step": 11520
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.287993431091309,
      "learning_rate": 2.1175e-05,
      "loss": 3.1158,
      "step": 11530
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.405036926269531,
      "learning_rate": 2.115e-05,
      "loss": 3.3578,
      "step": 11540
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.055052757263184,
      "learning_rate": 2.1125000000000002e-05,
      "loss": 3.0637,
      "step": 11550
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.332608222961426,
      "learning_rate": 2.11e-05,
      "loss": 2.9813,
      "step": 11560
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.564532279968262,
      "learning_rate": 2.1075e-05,
      "loss": 3.2328,
      "step": 11570
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.725135803222656,
      "learning_rate": 2.105e-05,
      "loss": 2.9049,
      "step": 11580
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.311195373535156,
      "learning_rate": 2.1025e-05,
      "loss": 3.2773,
      "step": 11590
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.981928825378418,
      "learning_rate": 2.1e-05,
      "loss": 3.2111,
      "step": 11600
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.538381576538086,
      "learning_rate": 2.0975e-05,
      "loss": 3.2207,
      "step": 11610
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.411704063415527,
      "learning_rate": 2.095e-05,
      "loss": 3.1434,
      "step": 11620
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.768136978149414,
      "learning_rate": 2.0925e-05,
      "loss": 2.9553,
      "step": 11630
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.414033889770508,
      "learning_rate": 2.09e-05,
      "loss": 3.2787,
      "step": 11640
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.792290687561035,
      "learning_rate": 2.0875e-05,
      "loss": 3.0781,
      "step": 11650
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.606579303741455,
      "learning_rate": 2.085e-05,
      "loss": 3.0338,
      "step": 11660
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.978647232055664,
      "learning_rate": 2.0825e-05,
      "loss": 2.8834,
      "step": 11670
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.722282409667969,
      "learning_rate": 2.08e-05,
      "loss": 3.2701,
      "step": 11680
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.53856086730957,
      "learning_rate": 2.0775e-05,
      "loss": 3.0615,
      "step": 11690
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.301725387573242,
      "learning_rate": 2.075e-05,
      "loss": 3.0773,
      "step": 11700
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.531158447265625,
      "learning_rate": 2.0725e-05,
      "loss": 3.2672,
      "step": 11710
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.775588989257812,
      "learning_rate": 2.07e-05,
      "loss": 3.2586,
      "step": 11720
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.068984985351562,
      "learning_rate": 2.0675e-05,
      "loss": 3.1908,
      "step": 11730
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.3004732131958,
      "learning_rate": 2.065e-05,
      "loss": 3.2094,
      "step": 11740
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.95044994354248,
      "learning_rate": 2.0625e-05,
      "loss": 3.0123,
      "step": 11750
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.726224899291992,
      "learning_rate": 2.06e-05,
      "loss": 2.8905,
      "step": 11760
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.051295280456543,
      "learning_rate": 2.0575e-05,
      "loss": 3.1328,
      "step": 11770
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.385851860046387,
      "learning_rate": 2.055e-05,
      "loss": 2.9551,
      "step": 11780
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.763376235961914,
      "learning_rate": 2.0525e-05,
      "loss": 3.2826,
      "step": 11790
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.159791946411133,
      "learning_rate": 2.05e-05,
      "loss": 3.3051,
      "step": 11800
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.846031188964844,
      "learning_rate": 2.0475e-05,
      "loss": 2.7531,
      "step": 11810
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.536703109741211,
      "learning_rate": 2.045e-05,
      "loss": 3.1828,
      "step": 11820
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.9590482711792,
      "learning_rate": 2.0425e-05,
      "loss": 2.8852,
      "step": 11830
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.307031631469727,
      "learning_rate": 2.04e-05,
      "loss": 3.3592,
      "step": 11840
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.411665916442871,
      "learning_rate": 2.0375e-05,
      "loss": 3.1895,
      "step": 11850
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.661751747131348,
      "learning_rate": 2.035e-05,
      "loss": 3.3037,
      "step": 11860
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.271215438842773,
      "learning_rate": 2.0325e-05,
      "loss": 3.1383,
      "step": 11870
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.399166107177734,
      "learning_rate": 2.0300000000000002e-05,
      "loss": 3.4535,
      "step": 11880
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.458670616149902,
      "learning_rate": 2.0275e-05,
      "loss": 3.115,
      "step": 11890
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.783821105957031,
      "learning_rate": 2.025e-05,
      "loss": 3.2703,
      "step": 11900
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.527104377746582,
      "learning_rate": 2.0225000000000004e-05,
      "loss": 3.4018,
      "step": 11910
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.380590438842773,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 3.1316,
      "step": 11920
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.53467082977295,
      "learning_rate": 2.0175000000000003e-05,
      "loss": 3.1666,
      "step": 11930
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.813859939575195,
      "learning_rate": 2.0150000000000002e-05,
      "loss": 3.1766,
      "step": 11940
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.772141456604004,
      "learning_rate": 2.0125e-05,
      "loss": 3.7025,
      "step": 11950
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.548638343811035,
      "learning_rate": 2.01e-05,
      "loss": 3.1514,
      "step": 11960
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.612127304077148,
      "learning_rate": 2.0075000000000003e-05,
      "loss": 3.2818,
      "step": 11970
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.719472885131836,
      "learning_rate": 2.0050000000000003e-05,
      "loss": 3.0355,
      "step": 11980
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.02811336517334,
      "learning_rate": 2.0025000000000002e-05,
      "loss": 3.2217,
      "step": 11990
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.660993576049805,
      "learning_rate": 2e-05,
      "loss": 3.1766,
      "step": 12000
    },
    {
      "epoch": 0.1,
      "eval_bleu-4": 0.03434638952424084,
      "eval_rouge-1": 32.39732,
      "eval_rouge-2": 7.303921999999999,
      "eval_rouge-l": 25.324324,
      "eval_runtime": 43.0019,
      "eval_samples_per_second": 1.163,
      "eval_steps_per_second": 0.093,
      "step": 12000
    },
    {
      "epoch": 0.1,
      "grad_norm": 11.0152006149292,
      "learning_rate": 1.9975e-05,
      "loss": 3.2953,
      "step": 12010
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.50110149383545,
      "learning_rate": 1.995e-05,
      "loss": 3.1701,
      "step": 12020
    },
    {
      "epoch": 0.1,
      "grad_norm": 8.180383682250977,
      "learning_rate": 1.9925000000000003e-05,
      "loss": 3.3301,
      "step": 12030
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.249136924743652,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 3.349,
      "step": 12040
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.211135864257812,
      "learning_rate": 1.9875000000000002e-05,
      "loss": 3.2258,
      "step": 12050
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.252791404724121,
      "learning_rate": 1.985e-05,
      "loss": 3.3201,
      "step": 12060
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.690975189208984,
      "learning_rate": 1.9825e-05,
      "loss": 3.1623,
      "step": 12070
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.802528381347656,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 2.9212,
      "step": 12080
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.53886890411377,
      "learning_rate": 1.9775000000000003e-05,
      "loss": 3.1801,
      "step": 12090
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.091551780700684,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 3.2889,
      "step": 12100
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.81486988067627,
      "learning_rate": 1.9725000000000002e-05,
      "loss": 3.0396,
      "step": 12110
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.765069007873535,
      "learning_rate": 1.97e-05,
      "loss": 3.2195,
      "step": 12120
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.061975479125977,
      "learning_rate": 1.9675e-05,
      "loss": 3.208,
      "step": 12130
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.674606323242188,
      "learning_rate": 1.9650000000000003e-05,
      "loss": 3.0797,
      "step": 12140
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.192659378051758,
      "learning_rate": 1.9625000000000003e-05,
      "loss": 3.1027,
      "step": 12150
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.411627769470215,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 2.8233,
      "step": 12160
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.747429847717285,
      "learning_rate": 1.9575e-05,
      "loss": 3.2881,
      "step": 12170
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.220840454101562,
      "learning_rate": 1.955e-05,
      "loss": 3.048,
      "step": 12180
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.397270202636719,
      "learning_rate": 1.9525e-05,
      "loss": 3.2984,
      "step": 12190
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.361661911010742,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.3156,
      "step": 12200
    },
    {
      "epoch": 0.11,
      "grad_norm": 12.682975769042969,
      "learning_rate": 1.9475000000000002e-05,
      "loss": 3.5965,
      "step": 12210
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.023113250732422,
      "learning_rate": 1.9450000000000002e-05,
      "loss": 3.3611,
      "step": 12220
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.343891143798828,
      "learning_rate": 1.9425e-05,
      "loss": 3.2336,
      "step": 12230
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.330184936523438,
      "learning_rate": 1.94e-05,
      "loss": 3.2309,
      "step": 12240
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.795830726623535,
      "learning_rate": 1.9375e-05,
      "loss": 3.3018,
      "step": 12250
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.34156608581543,
      "learning_rate": 1.9350000000000003e-05,
      "loss": 3.0469,
      "step": 12260
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.178937911987305,
      "learning_rate": 1.9325000000000002e-05,
      "loss": 3.0863,
      "step": 12270
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.843210220336914,
      "learning_rate": 1.93e-05,
      "loss": 2.9578,
      "step": 12280
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.122249603271484,
      "learning_rate": 1.9275e-05,
      "loss": 2.8531,
      "step": 12290
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.68132209777832,
      "learning_rate": 1.925e-05,
      "loss": 2.7936,
      "step": 12300
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.121850967407227,
      "learning_rate": 1.9225e-05,
      "loss": 3.3334,
      "step": 12310
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.422341346740723,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 3.5145,
      "step": 12320
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.994162559509277,
      "learning_rate": 1.9175000000000002e-05,
      "loss": 2.7502,
      "step": 12330
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.472864151000977,
      "learning_rate": 1.915e-05,
      "loss": 3.1949,
      "step": 12340
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.931612968444824,
      "learning_rate": 1.9125e-05,
      "loss": 3.0693,
      "step": 12350
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.55325698852539,
      "learning_rate": 1.91e-05,
      "loss": 3.255,
      "step": 12360
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.758121490478516,
      "learning_rate": 1.9075000000000003e-05,
      "loss": 3.1316,
      "step": 12370
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.493703842163086,
      "learning_rate": 1.9050000000000002e-05,
      "loss": 3.2043,
      "step": 12380
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.13907527923584,
      "learning_rate": 1.9025e-05,
      "loss": 3.2707,
      "step": 12390
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.909205436706543,
      "learning_rate": 1.9e-05,
      "loss": 3.2859,
      "step": 12400
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.7149019241333,
      "learning_rate": 1.8975e-05,
      "loss": 3.1539,
      "step": 12410
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.523591995239258,
      "learning_rate": 1.895e-05,
      "loss": 3.0447,
      "step": 12420
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.61915111541748,
      "learning_rate": 1.8925000000000003e-05,
      "loss": 3.3125,
      "step": 12430
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.031086921691895,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 3.1941,
      "step": 12440
    },
    {
      "epoch": 0.11,
      "grad_norm": 12.020844459533691,
      "learning_rate": 1.8875e-05,
      "loss": 3.0805,
      "step": 12450
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.899312019348145,
      "learning_rate": 1.885e-05,
      "loss": 3.3115,
      "step": 12460
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.06385326385498,
      "learning_rate": 1.8825e-05,
      "loss": 3.2211,
      "step": 12470
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.872589111328125,
      "learning_rate": 1.88e-05,
      "loss": 3.1139,
      "step": 12480
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.164355278015137,
      "learning_rate": 1.8775000000000002e-05,
      "loss": 3.2037,
      "step": 12490
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.178683280944824,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 3.4867,
      "step": 12500
    },
    {
      "epoch": 0.11,
      "eval_bleu-4": 0.03768361094759555,
      "eval_rouge-1": 32.030482,
      "eval_rouge-2": 7.50819,
      "eval_rouge-l": 25.452164000000003,
      "eval_runtime": 40.1638,
      "eval_samples_per_second": 1.245,
      "eval_steps_per_second": 0.1,
      "step": 12500
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.297080039978027,
      "learning_rate": 1.8725e-05,
      "loss": 3.0678,
      "step": 12510
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.233997344970703,
      "learning_rate": 1.87e-05,
      "loss": 3.0107,
      "step": 12520
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.50242805480957,
      "learning_rate": 1.8675e-05,
      "loss": 3.0973,
      "step": 12530
    },
    {
      "epoch": 0.11,
      "grad_norm": 12.134260177612305,
      "learning_rate": 1.865e-05,
      "loss": 3.0424,
      "step": 12540
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.885358810424805,
      "learning_rate": 1.8625000000000002e-05,
      "loss": 3.1047,
      "step": 12550
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.184833526611328,
      "learning_rate": 1.86e-05,
      "loss": 3.3924,
      "step": 12560
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.624944686889648,
      "learning_rate": 1.8575e-05,
      "loss": 3.2834,
      "step": 12570
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.729201316833496,
      "learning_rate": 1.855e-05,
      "loss": 3.298,
      "step": 12580
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.255102157592773,
      "learning_rate": 1.8525e-05,
      "loss": 3.2361,
      "step": 12590
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.026860237121582,
      "learning_rate": 1.85e-05,
      "loss": 3.2943,
      "step": 12600
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.921436309814453,
      "learning_rate": 1.8475000000000002e-05,
      "loss": 3.3385,
      "step": 12610
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.252222061157227,
      "learning_rate": 1.845e-05,
      "loss": 3.2596,
      "step": 12620
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.0001220703125,
      "learning_rate": 1.8425e-05,
      "loss": 3.1066,
      "step": 12630
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.227383613586426,
      "learning_rate": 1.84e-05,
      "loss": 3.4043,
      "step": 12640
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.822629928588867,
      "learning_rate": 1.8375e-05,
      "loss": 3.1445,
      "step": 12650
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.232038497924805,
      "learning_rate": 1.8350000000000002e-05,
      "loss": 3.3795,
      "step": 12660
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.227112770080566,
      "learning_rate": 1.8325e-05,
      "loss": 3.3398,
      "step": 12670
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.9171724319458,
      "learning_rate": 1.83e-05,
      "loss": 3.3289,
      "step": 12680
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.10137939453125,
      "learning_rate": 1.8275e-05,
      "loss": 3.0338,
      "step": 12690
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.510916709899902,
      "learning_rate": 1.825e-05,
      "loss": 3.1021,
      "step": 12700
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.14842414855957,
      "learning_rate": 1.8225e-05,
      "loss": 2.9086,
      "step": 12710
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.590961456298828,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 3.1477,
      "step": 12720
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.714714050292969,
      "learning_rate": 1.8175e-05,
      "loss": 3.3619,
      "step": 12730
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.129484176635742,
      "learning_rate": 1.815e-05,
      "loss": 2.9928,
      "step": 12740
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.089155197143555,
      "learning_rate": 1.8125e-05,
      "loss": 3.3184,
      "step": 12750
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.898984909057617,
      "learning_rate": 1.81e-05,
      "loss": 3.1582,
      "step": 12760
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.540302276611328,
      "learning_rate": 1.8075e-05,
      "loss": 3.3428,
      "step": 12770
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.204934120178223,
      "learning_rate": 1.805e-05,
      "loss": 3.2355,
      "step": 12780
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.885274887084961,
      "learning_rate": 1.8025e-05,
      "loss": 3.0588,
      "step": 12790
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.1950044631958,
      "learning_rate": 1.8e-05,
      "loss": 3.3813,
      "step": 12800
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.826818466186523,
      "learning_rate": 1.7975e-05,
      "loss": 3.4039,
      "step": 12810
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.468544006347656,
      "learning_rate": 1.795e-05,
      "loss": 3.4609,
      "step": 12820
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.33541202545166,
      "learning_rate": 1.7925e-05,
      "loss": 3.302,
      "step": 12830
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.318136215209961,
      "learning_rate": 1.79e-05,
      "loss": 2.7105,
      "step": 12840
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.793097496032715,
      "learning_rate": 1.7875e-05,
      "loss": 3.1684,
      "step": 12850
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.352694511413574,
      "learning_rate": 1.785e-05,
      "loss": 3.4752,
      "step": 12860
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.133440017700195,
      "learning_rate": 1.7825e-05,
      "loss": 3.4111,
      "step": 12870
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.024212837219238,
      "learning_rate": 1.78e-05,
      "loss": 2.9951,
      "step": 12880
    },
    {
      "epoch": 0.11,
      "grad_norm": 12.0820951461792,
      "learning_rate": 1.7775e-05,
      "loss": 3.2996,
      "step": 12890
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.164604187011719,
      "learning_rate": 1.775e-05,
      "loss": 3.4641,
      "step": 12900
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.070513725280762,
      "learning_rate": 1.7725e-05,
      "loss": 3.119,
      "step": 12910
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.60260009765625,
      "learning_rate": 1.77e-05,
      "loss": 3.3225,
      "step": 12920
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.314271926879883,
      "learning_rate": 1.7675e-05,
      "loss": 3.127,
      "step": 12930
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.990445137023926,
      "learning_rate": 1.765e-05,
      "loss": 3.0027,
      "step": 12940
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.554380416870117,
      "learning_rate": 1.7625e-05,
      "loss": 3.0137,
      "step": 12950
    },
    {
      "epoch": 0.11,
      "grad_norm": 9.869580268859863,
      "learning_rate": 1.76e-05,
      "loss": 3.0059,
      "step": 12960
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.756031036376953,
      "learning_rate": 1.7575e-05,
      "loss": 3.3396,
      "step": 12970
    },
    {
      "epoch": 0.11,
      "grad_norm": 10.101058006286621,
      "learning_rate": 1.755e-05,
      "loss": 3.1744,
      "step": 12980
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.48719596862793,
      "learning_rate": 1.7525e-05,
      "loss": 3.2434,
      "step": 12990
    },
    {
      "epoch": 0.11,
      "grad_norm": 8.313504219055176,
      "learning_rate": 1.75e-05,
      "loss": 3.2496,
      "step": 13000
    },
    {
      "epoch": 0.11,
      "eval_bleu-4": 0.03667098843364327,
      "eval_rouge-1": 32.913116,
      "eval_rouge-2": 7.4508,
      "eval_rouge-l": 25.406682000000004,
      "eval_runtime": 26.8061,
      "eval_samples_per_second": 1.865,
      "eval_steps_per_second": 0.149,
      "step": 13000
    }
  ],
  "logging_steps": 10,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 5.758155300909466e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
